<!DOCTYPE html>

<html lang="en" data-content_root="./">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Policies documentation &#8212; PyMAB 0.1.0-alpha.1 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/basic_mod.css?v=9b2032db" />
    <script src="_static/documentation_options.js?v=6940f236"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <script src="_static/js/petite-vue.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Game documentation" href="game.html" />
    <link rel="prev" title="PyMAB documentation" href="index.html" /> 
  </head><body data-dark_mode_code_blocks="true">

<div id="top_nav">
    

    <nav>
        
            
        

        <p id="toggle_sidebar">
            <a href="#" title="Toggle sidebar">|||</a>
        </p>
        <h1><a href="index.html" title="Go to homepage">PyMAB 0.1.0-alpha.1 documentation</a></h1>

        <a id="mode_toggle" href="#" @click.prevent="handleClick" :title="mode">
    <template v-if="mode == 'light'">
        <svg width="100%" height="100%" viewBox="0 0 79 80" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linejoin:round;stroke-miterlimit:2;"><g id="mode_light"><rect id="Bounds" x="0" y="-0" width="78.623" height="79.049" style="fill:none;"/><circle cx="39.311" cy="39.524" r="15.734" style="fill:#fff;"/><g id="beams"><g id="beam"><path id="beam1" serif:id="beam" d="M44.212,4.901c0,-2.705 -2.196,-4.901 -4.901,-4.901c-2.704,-0 -4.9,2.196 -4.9,4.901l-0,9.614c-0,2.705 2.196,4.901 4.9,4.901c2.705,0 4.901,-2.196 4.901,-4.901l0,-9.614Z" style="fill:#fff;"/></g><g id="beam2" serif:id="beam"><path id="beam3" serif:id="beam" d="M67.48,18.073c1.913,-1.912 1.913,-5.018 0,-6.931c-1.912,-1.912 -5.018,-1.912 -6.931,0l-6.798,6.799c-1.912,1.912 -1.912,5.018 0,6.931c1.913,1.912 5.018,1.912 6.931,-0l6.798,-6.799Z" style="fill:#fff;"/></g><g id="beam4" serif:id="beam"><path id="beam5" serif:id="beam" d="M25.728,61.108c1.912,-1.913 1.912,-5.018 -0,-6.931c-1.913,-1.913 -5.019,-1.913 -6.931,-0l-6.799,6.798c-1.912,1.913 -1.912,5.019 0,6.931c1.913,1.913 5.019,1.913 6.931,0l6.799,-6.798Z" style="fill:#fff;"/></g><g id="beam6" serif:id="beam"><path id="beam7" serif:id="beam" d="M60.682,54.177c-1.913,-1.913 -5.018,-1.913 -6.931,-0c-1.912,1.913 -1.912,5.018 0,6.931l6.798,6.798c1.913,1.913 5.019,1.913 6.931,0c1.913,-1.912 1.913,-5.018 0,-6.931l-6.798,-6.798Z" style="fill:#fff;"/></g><g id="beam8" serif:id="beam"><path id="beam9" serif:id="beam" d="M4.901,34.623c-2.705,0 -4.901,2.196 -4.901,4.901c0,2.705 2.196,4.901 4.901,4.901l9.614,0c2.705,0 4.901,-2.196 4.901,-4.901c0,-2.705 -2.196,-4.901 -4.901,-4.901l-9.614,0Z" style="fill:#fff;"/></g><g id="beam10" serif:id="beam"><path id="beam11" serif:id="beam" d="M44.212,64.534c0,-2.705 -2.196,-4.901 -4.901,-4.901c-2.704,-0 -4.9,2.196 -4.9,4.901l-0,9.614c-0,2.705 2.196,4.901 4.9,4.901c2.705,-0 4.901,-2.196 4.901,-4.901l0,-9.614Z" style="fill:#fff;"/></g><g id="beam12" serif:id="beam"><path id="beam13" serif:id="beam" d="M18.929,11.142c-1.912,-1.912 -5.018,-1.912 -6.931,0c-1.912,1.913 -1.912,5.019 0,6.931l6.799,6.799c1.912,1.912 5.018,1.912 6.931,-0c1.912,-1.913 1.912,-5.019 -0,-6.931l-6.799,-6.799Z" style="fill:#fff;"/></g><g id="beam14" serif:id="beam"><path id="beam15" serif:id="beam" d="M64.108,34.623c-2.705,0 -4.901,2.196 -4.901,4.901c-0,2.705 2.196,4.901 4.901,4.901l9.614,0c2.705,0 4.901,-2.196 4.901,-4.901c-0,-2.705 -2.196,-4.901 -4.901,-4.901l-9.614,0Z" style="fill:#fff;"/></g></g></g></svg>
    </template>

    <template v-if="mode == 'dark'">
        <svg width="100%" height="100%" viewBox="0 0 79 80" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linejoin:round;stroke-miterlimit:2;"><g id="mode_dark"><rect id="Bounds" x="0" y="-0" width="78.623" height="79.049" style="fill:none;"/><circle cx="39.311" cy="39.524" r="15.734" style="fill:#fff;"/><g id="beams"><g id="beam"><path id="beam1" serif:id="beam" d="M44.212,14.515c0,-2.705 -2.196,-4.901 -4.901,-4.901c-2.704,0 -4.901,2.196 -4.901,4.901c0,2.705 2.197,4.901 4.901,4.901c2.705,0 4.901,-2.196 4.901,-4.901Z" style="fill:#fff;"/></g><g id="beam2" serif:id="beam"><path id="beam3" serif:id="beam" d="M60.662,24.892c1.902,-1.902 1.902,-4.99 0,-6.892l-0.04,-0.039c-1.901,-1.902 -4.989,-1.902 -6.891,-0c-1.901,1.901 -1.901,4.989 0,6.891l0.04,0.04c1.902,1.901 4.989,1.901 6.891,-0Z" style="fill:#fff;"/></g><g id="beam4" serif:id="beam"><path id="beam5" serif:id="beam" d="M25.732,61.103c1.91,-1.91 1.91,-5.011 0,-6.921l-0.009,-0.01c-1.91,-1.91 -5.012,-1.91 -6.921,-0c-1.91,1.91 -1.91,5.011 -0,6.921l0.01,0.01c1.909,1.91 5.011,1.91 6.92,-0Z" style="fill:#fff;"/></g><g id="beam6" serif:id="beam"><path id="beam7" serif:id="beam" d="M60.672,54.167c-1.907,-1.907 -5.004,-1.907 -6.911,0l-0.02,0.02c-1.907,1.907 -1.907,5.004 0,6.911c1.907,1.907 5.004,1.907 6.911,-0l0.02,-0.02c1.907,-1.907 1.907,-5.004 0,-6.911Z" style="fill:#fff;"/></g><g id="beam8" serif:id="beam"><path id="beam9" serif:id="beam" d="M14.52,34.623c-2.702,0 -4.896,2.194 -4.896,4.896l0,0.01c0,2.702 2.194,4.896 4.896,4.896c2.702,0 4.896,-2.194 4.896,-4.896l-0,-0.01c-0,-2.702 -2.194,-4.896 -4.896,-4.896Z" style="fill:#fff;"/></g><g id="beam10" serif:id="beam"><path id="beam11" serif:id="beam" d="M44.212,64.534c0,-2.705 -2.196,-4.901 -4.901,-4.901c-2.704,-0 -4.901,2.196 -4.901,4.901c0,2.704 2.197,4.9 4.901,4.9c2.705,0 4.901,-2.196 4.901,-4.9Z" style="fill:#fff;"/></g><g id="beam12" serif:id="beam"><path id="beam13" serif:id="beam" d="M25.73,17.943c-1.911,-1.911 -5.015,-1.911 -6.926,0l-0.005,0.005c-1.911,1.911 -1.911,5.015 0,6.926c1.911,1.911 5.015,1.911 6.926,0l0.005,-0.005c1.911,-1.911 1.911,-5.014 -0,-6.926Z" style="fill:#fff;"/></g><g id="beam14" serif:id="beam"><path id="beam15" serif:id="beam" d="M64.098,34.623c-2.699,0 -4.891,2.192 -4.891,4.892l-0,0.019c-0,2.699 2.192,4.891 4.891,4.891c2.7,0 4.892,-2.192 4.892,-4.891l0,-0.019c0,-2.7 -2.192,-4.892 -4.892,-4.892Z" style="fill:#fff;"/></g></g></g></svg>
    </template>

    <template v-if="mode == 'darkest'">
        <svg width="100%" height="100%" viewBox="0 0 79 80" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linejoin:round;stroke-miterlimit:2;"><g id="mode_darkest"><rect id="Bounds" x="0" y="-0" width="78.623" height="79.049" style="fill:none;"/><path d="M39.315,23.791c8.684,-0 15.734,7.05 15.734,15.733c0,8.684 -7.05,15.734 -15.734,15.734c-8.683,0 -15.733,-7.05 -15.733,-15.734c-0,-8.683 7.05,-15.733 15.733,-15.733Zm0,4.737c6.069,0 10.997,4.927 10.997,10.996c-0,6.069 -4.928,10.996 -10.997,10.996c-6.068,0 -10.996,-4.927 -10.996,-10.996c0,-6.069 4.928,-10.996 10.996,-10.996Z" style="fill:#fff;"/><g id="beams"><g id="beam"><path id="beam1" serif:id="beam" d="M44.216,14.515c0,-2.705 -2.196,-4.901 -4.901,-4.901c-2.704,0 -4.9,2.196 -4.9,4.901c-0,2.705 2.196,4.901 4.9,4.901c2.705,0 4.901,-2.196 4.901,-4.901Z" style="fill:#fff;"/></g><g id="beam2" serif:id="beam"><path id="beam3" serif:id="beam" d="M60.666,24.892c1.902,-1.902 1.902,-4.99 0,-6.892l-0.04,-0.039c-1.901,-1.902 -4.989,-1.902 -6.891,-0c-1.901,1.901 -1.901,4.989 0,6.891l0.04,0.04c1.902,1.901 4.99,1.901 6.891,-0Z" style="fill:#fff;"/></g><g id="beam4" serif:id="beam"><path id="beam5" serif:id="beam" d="M25.737,61.103c1.909,-1.91 1.909,-5.011 -0,-6.921l-0.01,-0.01c-1.91,-1.91 -5.011,-1.91 -6.921,-0c-1.91,1.91 -1.91,5.011 -0,6.921l0.01,0.01c1.91,1.91 5.011,1.91 6.921,-0Z" style="fill:#fff;"/></g><g id="beam6" serif:id="beam"><path id="beam7" serif:id="beam" d="M60.676,54.167c-1.907,-1.907 -5.004,-1.907 -6.911,0l-0.02,0.02c-1.907,1.907 -1.907,5.004 0,6.911c1.907,1.907 5.004,1.907 6.911,-0l0.02,-0.02c1.907,-1.907 1.907,-5.004 0,-6.911Z" style="fill:#fff;"/></g><g id="beam8" serif:id="beam"><path id="beam9" serif:id="beam" d="M14.524,34.623c-2.702,0 -4.896,2.194 -4.896,4.896l0,0.01c0,2.702 2.194,4.896 4.896,4.896c2.702,0 4.896,-2.194 4.896,-4.896l0,-0.01c0,-2.702 -2.194,-4.896 -4.896,-4.896Z" style="fill:#fff;"/></g><g id="beam10" serif:id="beam"><path id="beam11" serif:id="beam" d="M44.216,64.534c0,-2.705 -2.196,-4.901 -4.901,-4.901c-2.704,-0 -4.9,2.196 -4.9,4.901c-0,2.704 2.196,4.9 4.9,4.9c2.705,0 4.901,-2.196 4.901,-4.9Z" style="fill:#fff;"/></g><g id="beam12" serif:id="beam"><path id="beam13" serif:id="beam" d="M25.734,17.943c-1.911,-1.911 -5.015,-1.911 -6.926,0l-0.005,0.005c-1.911,1.911 -1.911,5.015 0,6.926c1.911,1.911 5.015,1.911 6.926,0l0.005,-0.005c1.911,-1.911 1.911,-5.014 0,-6.926Z" style="fill:#fff;"/></g><g id="beam14" serif:id="beam"><path id="beam15" serif:id="beam" d="M64.103,34.623c-2.7,0 -4.892,2.192 -4.892,4.892l-0,0.019c-0,2.699 2.192,4.891 4.892,4.891c2.699,0 4.891,-2.192 4.891,-4.891l0,-0.019c0,-2.7 -2.192,-4.892 -4.891,-4.892Z" style="fill:#fff;"/></g></g></g></svg>
    </template>
</a>

<script>
(function() {
    const LOCAL_STORAGE_KEY = 'piccoloThemeMode'

    var initialMode = localStorage.getItem(LOCAL_STORAGE_KEY)

    if (initialMode) {
        // Make sure the value in local storage is valid
        if (['light', 'dark', 'darkest'].indexOf(initialMode) == -1) {
            initialMode = 'light'
            localStorage.setItem(LOCAL_STORAGE_KEY, initialMode)
        }
    } else {
        // Check if the client prefers dark mode
        if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches) {
            initialMode = 'dark'
        } else {
            initialMode = 'light'
        }
        localStorage.setItem(LOCAL_STORAGE_KEY, initialMode)
    }

    document.documentElement.dataset.mode = initialMode

    PetiteVue.createApp({
        'mode': initialMode,
        handleClick() {
            let currentMode = this.mode

            if (currentMode == 'light') {
                this.mode = 'dark'
            } else if (currentMode == 'dark') {
                this.mode = 'darkest'
            } else if (currentMode == 'darkest') {
                this.mode = 'light'
            }

            document.documentElement.dataset.mode = this.mode
            localStorage.setItem(LOCAL_STORAGE_KEY, this.mode)

            console.log(this.mode)
        }
    }).mount('#mode_toggle')
})()
</script>
            <p class="mobile_search_link">
                <a href="search.html" title="Search">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 65 64" fill-rule="evenodd" stroke-linejoin="round" stroke-miterlimit="2">
                        <path d="M14.873 40.009c-2.315-3.943-3.642-8.532-3.642-13.429C11.231 11.91 23.141 0 37.811 0s26.58 11.91 26.58 26.58-11.91 26.58-26.58 26.58a26.44 26.44 0 0 1-14.277-4.161L9.739 62.794a3.12 3.12 0 0 1-4.413 0L.913 58.382c-1.217-1.218-1.217-3.196 0-4.413l13.96-13.96zM37.811 8.054c10.225 0 18.526 8.301 18.526 18.526s-8.301 18.526-18.526 18.526-18.526-8.301-18.526-18.526S27.586 8.054 37.811 8.054z" fill="#fff" />
                    </svg>
                </a>
            </p>
        

        <div class="searchbox_wrapper">
            
<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
    </nav>
</div>

    
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper"><p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Policies documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="game.html">Game documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="reward_distribution.html">Reward Distribution documentation</a></li>
</ul>

        </div>
      </div>


    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section id="policies-documentation">
<h1>Policies documentation<a class="headerlink" href="#policies-documentation" title="Link to this heading">¶</a></h1>
<section id="policy-policy-py">
<h2>Policy (policy.py)<a class="headerlink" href="#policy-policy-py" title="Link to this heading">¶</a></h2>
<p>The Policy class serves as the base class for all bandit algorithms in PyMultiBandits. It defines the common interface and basic functionality that all specific policy implementations should follow.</p>
<dl class="py function" id="module-pymab.policies.policy">
<dt class="sig sig-object py" id="pymab.policies.policy.no_context_func">
<span class="sig-name descname"><span class="pre">no_context_func</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/policy.html#no_context_func"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.policy.no_context_func" title="Link to this definition">¶</a></dt>
<dd><p>Dummy context function that does not generate any context.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pymab.policies.policy.Policy">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">Policy</span></span><a class="reference internal" href="_modules/pymab/policies/policy.html#Policy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.policy.Policy" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/abc.html#abc.ABC" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></a></p>
<p>Abstract base class for multi-armed bandit policies.</p>
<p>This class provides a framework for implementing various bandit algorithms.
It handles common functionality such as reward tracking, action selection,
and policy updates.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_bandits</strong> – Number of bandits (actions) available.</p></li>
<li><p><strong>optimistic_initialization</strong> – Initial Q-value for all actions. Defaults to 0.0.</p></li>
<li><p><strong>variance</strong> – Variance of the reward distribution. Defaults to 1.0.</p></li>
<li><p><strong>reward_distribution</strong> – Type of reward distribution (“gaussian”, “bernoulli”, or “uniform”).
Defaults to “gaussian”.</p></li>
<li><p><strong>context_func</strong> – Function to generate context. Defaults to no_context_func.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.policy.Policy.n_bandits">
<span class="sig-name descname"><span class="pre">n_bandits</span></span><a class="headerlink" href="#pymab.policies.policy.Policy.n_bandits" title="Link to this definition">¶</a></dt>
<dd><p>Number of available actions.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.policy.Policy.optimistic_initialization">
<span class="sig-name descname"><span class="pre">optimistic_initialization</span></span><a class="headerlink" href="#pymab.policies.policy.Policy.optimistic_initialization" title="Link to this definition">¶</a></dt>
<dd><p>Initial value for all action estimates.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.policy.Policy._Q_values">
<span class="sig-name descname"><span class="pre">_Q_values</span></span><a class="headerlink" href="#pymab.policies.policy.Policy._Q_values" title="Link to this definition">¶</a></dt>
<dd><p>True Q-values for each action.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.policy.Policy.current_step">
<span class="sig-name descname"><span class="pre">current_step</span></span><a class="headerlink" href="#pymab.policies.policy.Policy.current_step" title="Link to this definition">¶</a></dt>
<dd><p>Current time step in the learning process.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.policy.Policy.total_reward">
<span class="sig-name descname"><span class="pre">total_reward</span></span><a class="headerlink" href="#pymab.policies.policy.Policy.total_reward" title="Link to this definition">¶</a></dt>
<dd><p>Cumulative reward obtained.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.policy.Policy.times_selected">
<span class="sig-name descname"><span class="pre">times_selected</span></span><a class="headerlink" href="#pymab.policies.policy.Policy.times_selected" title="Link to this definition">¶</a></dt>
<dd><p>Selection count for each action.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.policy.Policy.actions_estimated_reward">
<span class="sig-name descname"><span class="pre">actions_estimated_reward</span></span><a class="headerlink" href="#pymab.policies.policy.Policy.actions_estimated_reward" title="Link to this definition">¶</a></dt>
<dd><p>Current reward estimates.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.policy.Policy.variance">
<span class="sig-name descname"><span class="pre">variance</span></span><a class="headerlink" href="#pymab.policies.policy.Policy.variance" title="Link to this definition">¶</a></dt>
<dd><p>Reward distribution variance.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.policy.Policy.reward_distribution">
<span class="sig-name descname"><span class="pre">reward_distribution</span></span><a class="headerlink" href="#pymab.policies.policy.Policy.reward_distribution" title="Link to this definition">¶</a></dt>
<dd><p>Reward distribution class.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Type</em>[<a class="reference internal" href="reward_distribution.html#pymab.reward_distribution.RewardDistribution" title="pymab.reward_distribution.RewardDistribution"><em>RewardDistribution</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.policy.Policy.context_func">
<span class="sig-name descname"><span class="pre">context_func</span></span><a class="headerlink" href="#pymab.policies.policy.Policy.context_func" title="Link to this definition">¶</a></dt>
<dd><p>Context generation function.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Callable</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.policy.Policy.rewards_history">
<span class="sig-name descname"><span class="pre">rewards_history</span></span><a class="headerlink" href="#pymab.policies.policy.Policy.rewards_history" title="Link to this definition">¶</a></dt>
<dd><p>History of rewards per action.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>List</em>[<em>List</em>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.policy.Policy.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_bandits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimistic_initialization=0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">variance=1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reward_distribution='gaussian'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_func=&lt;function</span> <span class="pre">no_context_func&gt;</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/policy.html#Policy.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.policy.Policy.__init__" title="Link to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_bandits</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>)</p></li>
<li><p><strong>optimistic_initialization</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>)</p></li>
<li><p><strong>variance</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>)</p></li>
<li><p><strong>reward_distribution</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>)</p></li>
<li><p><strong>context_func</strong> (<em>Callable</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>None</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.policy.Policy.get_reward_distribution">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_reward_distribution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/policy.html#Policy.get_reward_distribution"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.policy.Policy.get_reward_distribution" title="Link to this definition">¶</a></dt>
<dd><p>Get the reward distribution class based on the given name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Name of the reward distribution.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The corresponding reward distribution class.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If an unknown distribution name is provided.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Type</em>[<a class="reference internal" href="reward_distribution.html#pymab.reward_distribution.RewardDistribution" title="pymab.reward_distribution.RewardDistribution"><em>RewardDistribution</em></a>]</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Supported distributions are:
- ‘gaussian’: Normal distribution
- ‘bernoulli’: Binary distribution
- ‘uniform’: Uniform distribution</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.policy.Policy._get_actual_reward">
<span class="sig-name descname"><span class="pre">_get_actual_reward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_index</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/policy.html#Policy._get_actual_reward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.policy.Policy._get_actual_reward" title="Link to this definition">¶</a></dt>
<dd><p>Get the actual reward for a given action.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of the chosen action.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The reward value sampled from the distribution.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.policy.Policy._update">
<span class="sig-name descname"><span class="pre">_update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">chosen_action_index</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/policy.html#Policy._update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.policy.Policy._update" title="Link to this definition">¶</a></dt>
<dd><p>Update the policy based on the chosen action and received reward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>chosen_action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of the chosen action.</p></li>
<li><p><strong>*args</strong> – Variable length argument list.</p></li>
<li><p><strong>**kwargs</strong> – Arbitrary keyword arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The reward received for the chosen action.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.policy.Policy._update_estimate">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">_update_estimate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_index</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reward</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/policy.html#Policy._update_estimate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.policy.Policy._update_estimate" title="Link to this definition">¶</a></dt>
<dd><p>Update the estimated reward for a given action.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of the action to update.</p></li>
<li><p><strong>reward</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Reward received for the action.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>None</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.policy.Policy._update_sliding_window">
<span class="sig-name descname"><span class="pre">_update_sliding_window</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">chosen_action_index</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/policy.html#Policy._update_sliding_window"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.policy.Policy._update_sliding_window" title="Link to this definition">¶</a></dt>
<dd><p>Update the sliding window of rewards for a given action.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>chosen_action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of the chosen action.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>None</em></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method maintains a fixed-size window of recent rewards
and updates the estimated reward based on this window.</p>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pymab.policies.policy.Policy.Q_values">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">Q_values</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#pymab.policies.policy.Policy.Q_values" title="Link to this definition">¶</a></dt>
<dd><p>Get the true Q-values for all actions.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>List of true Q-values.</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If Q-values haven’t been set.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.policy.Policy.select_action">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">select_action</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/policy.html#Policy.select_action"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.policy.Policy.select_action" title="Link to this definition">¶</a></dt>
<dd><p>Select an action based on the policy.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>*args</strong> – Variable length argument list.</p></li>
<li><p><strong>**kwargs</strong> – Arbitrary keyword arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>Index of the chosen action (int)</p></li>
<li><p>Reward received for the action (float)</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>A tuple containing</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.policy.Policy.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/policy.html#Policy.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.policy.Policy.reset" title="Link to this definition">¶</a></dt>
<dd><p>Reset the policy to its initial state.</p>
<p>This method resets:
- Current step counter
- Total reward
- Action selection counts
- Estimated rewards
- Reward history</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.policy.Policy.plot_distribution">
<span class="sig-name descname"><span class="pre">plot_distribution</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/policy.html#Policy.plot_distribution"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.policy.Policy.plot_distribution" title="Link to this definition">¶</a></dt>
<dd><p>Plot the distributions of the expected reward for the current step.</p>
<p>This method visualizes the reward distributions for all actions, showing
both the estimated rewards and true rewards (if known).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method handles both Bernoulli and Gaussian reward distributions.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>None</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="bayesian-ucb-bayesian-ucb-py">
<h2>Bayesian UCB (bayesian_ucb.py)<a class="headerlink" href="#bayesian-ucb-bayesian-ucb-py" title="Link to this heading">¶</a></h2>
<p>Bayesian Upper Confidence Bound (UCB) is an advanced policy that uses Bayesian inference to balance exploration and exploitation. It maintains a probability distribution over the expected rewards of each arm and uses this to make decisions.</p>
<dl class="py class" id="module-pymab.policies.bayesian_ucb">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">BernoulliBayesianUCBPolicy</span></span><a class="reference internal" href="_modules/pymab/policies/bayesian_ucb.html#BernoulliBayesianUCBPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#pymab.policies.ucb.StationaryUCBPolicy" title="pymab.policies.ucb.StationaryUCBPolicy"><code class="xref py py-class docutils literal notranslate"><span class="pre">StationaryUCBPolicy</span></code></a></p>
<p>Implements a Bayesian Upper Confidence Bound (UCB) policy for Bernoulli bandits.</p>
<p>This policy uses Bayesian inference with a Beta prior to estimate the probability of success
for each arm, and selects actions based on an upper confidence bound of these estimates.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_bandits</strong> – Number of bandits (actions) available.</p></li>
<li><p><strong>optimistic_initialization</strong> – Initial Q-value for all actions. Defaults to 0.0.</p></li>
<li><p><strong>variance</strong> – Variance of the reward distribution. Defaults to 1.0.</p></li>
<li><p><strong>reward_distribution</strong> – Type of reward distribution. Must be “bernoulli”. Defaults to “bernoulli”.</p></li>
<li><p><strong>c</strong> – Exploration parameter for UCB calculation. Defaults to 1.0.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.successes">
<span class="sig-name descname"><span class="pre">successes</span></span><a class="headerlink" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.successes" title="Link to this definition">¶</a></dt>
<dd><p>Number of successful outcomes for each arm.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.failures">
<span class="sig-name descname"><span class="pre">failures</span></span><a class="headerlink" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.failures" title="Link to this definition">¶</a></dt>
<dd><p>Number of failed outcomes for each arm.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Theory:
The Bernoulli Bayesian UCB policy maintains a Beta distribution for each arm,
which represents the current belief about the probability of success. The policy
selects actions based on an upper confidence bound of these distributions,
balancing exploration and exploitation.</p>
<p>Optimizations:
- Uses numpy arrays for efficient storage and computation
- Implements optimistic initialization through Beta parameters
- Tracks successes and failures separately for quick updates</p>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.n_bandits">
<span class="sig-name descname"><span class="pre">n_bandits</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></em><a class="headerlink" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.n_bandits" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.optimistic_initialization">
<span class="sig-name descname"><span class="pre">optimistic_initialization</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></em><a class="headerlink" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.optimistic_initialization" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.current_step">
<span class="sig-name descname"><span class="pre">current_step</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></em><a class="headerlink" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.current_step" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.total_reward">
<span class="sig-name descname"><span class="pre">total_reward</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></em><a class="headerlink" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.total_reward" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.times_selected">
<span class="sig-name descname"><span class="pre">times_selected</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">np.array</span></em><a class="headerlink" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.times_selected" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.actions_estimated_reward">
<span class="sig-name descname"><span class="pre">actions_estimated_reward</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">np.array</span></em><a class="headerlink" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.actions_estimated_reward" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.variance">
<span class="sig-name descname"><span class="pre">variance</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></em><a class="headerlink" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.variance" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.reward_distribution">
<span class="sig-name descname"><span class="pre">reward_distribution</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="reward_distribution.html#pymab.reward_distribution.RewardDistribution" title="pymab.reward_distribution.RewardDistribution"><span class="pre">RewardDistribution</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.reward_distribution" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.c">
<span class="sig-name descname"><span class="pre">c</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></em><a class="headerlink" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.c" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_bandits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimistic_initialization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">variance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reward_distribution</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'bernoulli'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/bayesian_ucb.html#BernoulliBayesianUCBPolicy.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.__init__" title="Link to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_bandits</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>)</p></li>
<li><p><strong>optimistic_initialization</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>)</p></li>
<li><p><strong>variance</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>)</p></li>
<li><p><strong>reward_distribution</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>)</p></li>
<li><p><strong>c</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>None</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy._get_ucb_value">
<span class="sig-name descname"><span class="pre">_get_ucb_value</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_index</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/bayesian_ucb.html#BernoulliBayesianUCBPolicy._get_ucb_value"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy._get_ucb_value" title="Link to this definition">¶</a></dt>
<dd><p>Calculates the UCB value for a given action.</p>
<p>This method computes the upper confidence bound using the properties of the Beta distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of the action to calculate UCB for.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The calculated UCB value incorporating uncertainty from the Beta distribution.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The UCB value is computed using the mean and variance of the Beta distribution,
with the variance scaled by the exploration parameter and current step.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy._update">
<span class="sig-name descname"><span class="pre">_update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">chosen_action_index</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/bayesian_ucb.html#BernoulliBayesianUCBPolicy._update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy._update" title="Link to this definition">¶</a></dt>
<dd><p>Updates the policy after an action is taken.</p>
<p>This method updates the success and failure counts based on the observed reward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>chosen_action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of the chosen action.</p></li>
<li><p><strong>*args</strong> – Additional positional arguments.</p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The observed reward.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.Q_values">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">Q_values</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.Q_values" title="Link to this definition">¶</a></dt>
<dd><p>Get the true Q-values for all actions.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>List of true Q-values.</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If Q-values haven’t been set.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy._calculate_confidence_interval">
<span class="sig-name descname"><span class="pre">_calculate_confidence_interval</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_index</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy._calculate_confidence_interval" title="Link to this definition">¶</a></dt>
<dd><p>Calculate the confidence interval for the stationary UCB algorithm.</p>
<p>This method implements the standard UCB1 confidence interval calculation,
which assumes a stationary environment (i.e., reward distributions do not change over time).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – The index of the action to calculate the confidence interval for.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The calculated confidence interval.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
<dt class="field-even">Theory<span class="colon">:</span></dt>
<dd class="field-even"><p>The confidence interval is calculated as sqrt((c * log(t)) / n_a),
where c is the exploration parameter, t is the current time step,
and n_a is the number of times the action has been selected.</p>
</dd>
<dt class="field-odd">Optimization<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>Uses math.sqrt and math.log for efficient calculation.</p></li>
<li><p>Adds 1 to current_step to avoid log(0) in the first step.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy._get_actual_reward">
<span class="sig-name descname"><span class="pre">_get_actual_reward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_index</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy._get_actual_reward" title="Link to this definition">¶</a></dt>
<dd><p>Get the actual reward for a given action.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of the chosen action.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The reward value sampled from the distribution.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy._update_sliding_window">
<span class="sig-name descname"><span class="pre">_update_sliding_window</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">chosen_action_index</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy._update_sliding_window" title="Link to this definition">¶</a></dt>
<dd><p>Update the sliding window of rewards for a given action.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>chosen_action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of the chosen action.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>None</em></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method maintains a fixed-size window of recent rewards
and updates the estimated reward based on this window.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.get_reward_distribution">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_reward_distribution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.get_reward_distribution" title="Link to this definition">¶</a></dt>
<dd><p>Get the reward distribution class based on the given name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Name of the reward distribution.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The corresponding reward distribution class.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If an unknown distribution name is provided.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Type</em>[<a class="reference internal" href="reward_distribution.html#pymab.reward_distribution.RewardDistribution" title="pymab.reward_distribution.RewardDistribution"><em>RewardDistribution</em></a>]</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Supported distributions are:
- ‘gaussian’: Normal distribution
- ‘bernoulli’: Binary distribution
- ‘uniform’: Uniform distribution</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.plot_distribution">
<span class="sig-name descname"><span class="pre">plot_distribution</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.plot_distribution" title="Link to this definition">¶</a></dt>
<dd><p>Plot the distributions of the expected reward for the current step.</p>
<p>This method visualizes the reward distributions for all actions, showing
both the estimated rewards and true rewards (if known).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method handles both Bernoulli and Gaussian reward distributions.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>None</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.reset" title="Link to this definition">¶</a></dt>
<dd><p>Reset the policy to its initial state.</p>
<p>This method resets:
- Current step counter
- Total reward
- Action selection counts
- Estimated rewards
- Reward history</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.select_action">
<span class="sig-name descname"><span class="pre">select_action</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.select_action" title="Link to this definition">¶</a></dt>
<dd><p>Select the next action based on the UCB algorithm.</p>
<p>This method implements the action selection strategy of UCB:
1. Initially, it selects each action once to gather initial estimates.
2. After that, it chooses the action with the highest UCB value.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A tuple containing the index of the chosen action and the reward obtained from taking that action.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tuple</em>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>]</p>
</dd>
</dl>
<p>Examples:
Here’s how to use the <cite>select_action</cite> method:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">policy</span> <span class="o">=</span> <span class="n">UCBPolicy</span><span class="p">(</span><span class="n">n_bandits</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">action</span><span class="p">,</span> <span class="n">reward</span> <span class="o">=</span> <span class="n">policy</span><span class="o">.</span><span class="n">select_action</span><span class="p">()</span>
    <span class="c1"># Use the action and reward as needed</span>
</pre></div>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.rewards_history">
<span class="sig-name descname"><span class="pre">rewards_history</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.rewards_history" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">GaussianBayesianUCBPolicy</span></span><a class="reference internal" href="_modules/pymab/policies/bayesian_ucb.html#GaussianBayesianUCBPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#pymab.policies.ucb.StationaryUCBPolicy" title="pymab.policies.ucb.StationaryUCBPolicy"><code class="xref py py-class docutils literal notranslate"><span class="pre">StationaryUCBPolicy</span></code></a></p>
<p>Implements a Bayesian Upper Confidence Bound (UCB) policy for Gaussian-distributed rewards.</p>
<p>This policy uses a Normal distribution as a conjugate prior for Gaussian rewards.
It calculates the UCB value using the mean and variance of the posterior distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_bandits</strong> – Number of bandits (actions) available.</p></li>
<li><p><strong>optimistic_initialization</strong> – Initial Q-value for all actions. Defaults to 0.0.</p></li>
<li><p><strong>variance</strong> – Variance of the reward distribution. Defaults to 1.0.</p></li>
<li><p><strong>reward_distribution</strong> – Type of reward distribution. Must be “gaussian”. Defaults to “gaussian”.</p></li>
<li><p><strong>c</strong> – Exploration parameter for UCB calculation. Defaults to 1.0.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.sum_rewards">
<span class="sig-name descname"><span class="pre">sum_rewards</span></span><a class="headerlink" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.sum_rewards" title="Link to this definition">¶</a></dt>
<dd><p>Sum of rewards for each arm.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.sum_squared_rewards">
<span class="sig-name descname"><span class="pre">sum_squared_rewards</span></span><a class="headerlink" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.sum_squared_rewards" title="Link to this definition">¶</a></dt>
<dd><p>Sum of squared rewards for each arm.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The policy maintains running sums of rewards and squared rewards to efficiently
compute the posterior mean and variance for each arm. This allows for quick
updates and UCB calculations without storing full reward histories.</p>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.n_bandits">
<span class="sig-name descname"><span class="pre">n_bandits</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></em><a class="headerlink" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.n_bandits" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.optimistic_initialization">
<span class="sig-name descname"><span class="pre">optimistic_initialization</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></em><a class="headerlink" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.optimistic_initialization" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.current_step">
<span class="sig-name descname"><span class="pre">current_step</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></em><a class="headerlink" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.current_step" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.total_reward">
<span class="sig-name descname"><span class="pre">total_reward</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></em><a class="headerlink" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.total_reward" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.times_selected">
<span class="sig-name descname"><span class="pre">times_selected</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">np.array</span></em><a class="headerlink" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.times_selected" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.actions_estimated_reward">
<span class="sig-name descname"><span class="pre">actions_estimated_reward</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">np.array</span></em><a class="headerlink" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.actions_estimated_reward" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.variance">
<span class="sig-name descname"><span class="pre">variance</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></em><a class="headerlink" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.variance" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.reward_distribution">
<span class="sig-name descname"><span class="pre">reward_distribution</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="reward_distribution.html#pymab.reward_distribution.RewardDistribution" title="pymab.reward_distribution.RewardDistribution"><span class="pre">RewardDistribution</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.reward_distribution" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.c">
<span class="sig-name descname"><span class="pre">c</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></em><a class="headerlink" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.c" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_bandits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimistic_initialization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">variance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reward_distribution</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gaussian'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/bayesian_ucb.html#GaussianBayesianUCBPolicy.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.__init__" title="Link to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_bandits</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>)</p></li>
<li><p><strong>optimistic_initialization</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>)</p></li>
<li><p><strong>variance</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>)</p></li>
<li><p><strong>reward_distribution</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>)</p></li>
<li><p><strong>c</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>None</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy._get_ucb_value">
<span class="sig-name descname"><span class="pre">_get_ucb_value</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_index</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/bayesian_ucb.html#GaussianBayesianUCBPolicy._get_ucb_value"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy._get_ucb_value" title="Link to this definition">¶</a></dt>
<dd><p>Calculates the UCB value for a given action.</p>
<p>This method computes the upper confidence bound using the properties of the Normal distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of the action to calculate UCB for.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The calculated UCB value incorporating uncertainty from the Normal distribution.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Returns infinity for unselected actions to ensure initial exploration.
Uses the Normal distribution’s properties to compute a confidence bound
based on the empirical mean and variance.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy._update">
<span class="sig-name descname"><span class="pre">_update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">chosen_action_index</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/bayesian_ucb.html#GaussianBayesianUCBPolicy._update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy._update" title="Link to this definition">¶</a></dt>
<dd><p>Updates the policy after an action is taken.</p>
<p>This method updates the sum of rewards and sum of squared rewards based on the observed reward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>chosen_action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of the chosen action.</p></li>
<li><p><strong>*args</strong> – Additional positional arguments.</p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The observed reward.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.Q_values">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">Q_values</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.Q_values" title="Link to this definition">¶</a></dt>
<dd><p>Get the true Q-values for all actions.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>List of true Q-values.</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If Q-values haven’t been set.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy._calculate_confidence_interval">
<span class="sig-name descname"><span class="pre">_calculate_confidence_interval</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_index</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy._calculate_confidence_interval" title="Link to this definition">¶</a></dt>
<dd><p>Calculate the confidence interval for the stationary UCB algorithm.</p>
<p>This method implements the standard UCB1 confidence interval calculation,
which assumes a stationary environment (i.e., reward distributions do not change over time).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – The index of the action to calculate the confidence interval for.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The calculated confidence interval.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
<dt class="field-even">Theory<span class="colon">:</span></dt>
<dd class="field-even"><p>The confidence interval is calculated as sqrt((c * log(t)) / n_a),
where c is the exploration parameter, t is the current time step,
and n_a is the number of times the action has been selected.</p>
</dd>
<dt class="field-odd">Optimization<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>Uses math.sqrt and math.log for efficient calculation.</p></li>
<li><p>Adds 1 to current_step to avoid log(0) in the first step.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy._get_actual_reward">
<span class="sig-name descname"><span class="pre">_get_actual_reward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_index</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy._get_actual_reward" title="Link to this definition">¶</a></dt>
<dd><p>Get the actual reward for a given action.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of the chosen action.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The reward value sampled from the distribution.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy._update_sliding_window">
<span class="sig-name descname"><span class="pre">_update_sliding_window</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">chosen_action_index</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy._update_sliding_window" title="Link to this definition">¶</a></dt>
<dd><p>Update the sliding window of rewards for a given action.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>chosen_action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of the chosen action.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>None</em></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method maintains a fixed-size window of recent rewards
and updates the estimated reward based on this window.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.get_reward_distribution">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_reward_distribution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.get_reward_distribution" title="Link to this definition">¶</a></dt>
<dd><p>Get the reward distribution class based on the given name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Name of the reward distribution.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The corresponding reward distribution class.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If an unknown distribution name is provided.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Type</em>[<a class="reference internal" href="reward_distribution.html#pymab.reward_distribution.RewardDistribution" title="pymab.reward_distribution.RewardDistribution"><em>RewardDistribution</em></a>]</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Supported distributions are:
- ‘gaussian’: Normal distribution
- ‘bernoulli’: Binary distribution
- ‘uniform’: Uniform distribution</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.plot_distribution">
<span class="sig-name descname"><span class="pre">plot_distribution</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.plot_distribution" title="Link to this definition">¶</a></dt>
<dd><p>Plot the distributions of the expected reward for the current step.</p>
<p>This method visualizes the reward distributions for all actions, showing
both the estimated rewards and true rewards (if known).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method handles both Bernoulli and Gaussian reward distributions.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>None</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.reset" title="Link to this definition">¶</a></dt>
<dd><p>Reset the policy to its initial state.</p>
<p>This method resets:
- Current step counter
- Total reward
- Action selection counts
- Estimated rewards
- Reward history</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.select_action">
<span class="sig-name descname"><span class="pre">select_action</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.select_action" title="Link to this definition">¶</a></dt>
<dd><p>Select the next action based on the UCB algorithm.</p>
<p>This method implements the action selection strategy of UCB:
1. Initially, it selects each action once to gather initial estimates.
2. After that, it chooses the action with the highest UCB value.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A tuple containing the index of the chosen action and the reward obtained from taking that action.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tuple</em>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>]</p>
</dd>
</dl>
<p>Examples:
Here’s how to use the <cite>select_action</cite> method:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">policy</span> <span class="o">=</span> <span class="n">UCBPolicy</span><span class="p">(</span><span class="n">n_bandits</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">action</span><span class="p">,</span> <span class="n">reward</span> <span class="o">=</span> <span class="n">policy</span><span class="o">.</span><span class="n">select_action</span><span class="p">()</span>
    <span class="c1"># Use the action and reward as needed</span>
</pre></div>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.rewards_history">
<span class="sig-name descname"><span class="pre">rewards_history</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.rewards_history" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.BayesianUCBPolicy">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">BayesianUCBPolicy</span></span><a class="reference internal" href="_modules/pymab/policies/bayesian_ucb.html#BayesianUCBPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.bayesian_ucb.BayesianUCBPolicy" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Factory class for creating Bayesian UCB policies based on the reward distribution.</p>
<p>This class creates and returns either a BernoulliBayesianUCBPolicy or a GaussianBayesianUCBPolicy
based on the specified reward distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_bandits</strong> – Number of bandits (actions) available.</p></li>
<li><p><strong>optimistic_initialization</strong> – Initial Q-value for all actions. Defaults to 0.0.</p></li>
<li><p><strong>variance</strong> – Variance of the reward distribution. Defaults to 1.0.</p></li>
<li><p><strong>reward_distribution</strong> – Type of reward distribution (“bernoulli” or “gaussian”).
Defaults to “gaussian”.</p></li>
<li><p><strong>c</strong> – Exploration parameter for UCB calculation. Defaults to 1.0.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Either a BernoulliBayesianUCBPolicy or GaussianBayesianUCBPolicy instance.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If an unsupported reward distribution is specified.</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The choice between Bernoulli and Gaussian policies should be based on the
nature of the rewards in the problem being solved. Bernoulli is suitable
for binary outcomes, while Gaussian is better for continuous rewards.</p>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.bayesian_ucb.BayesianUCBPolicy.__new__">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">__new__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cls</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_bandits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimistic_initialization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">variance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reward_distribution</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gaussian'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/bayesian_ucb.html#BayesianUCBPolicy.__new__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.bayesian_ucb.BayesianUCBPolicy.__new__" title="Link to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_bandits</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>)</p></li>
<li><p><strong>optimistic_initialization</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>)</p></li>
<li><p><strong>variance</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>)</p></li>
<li><p><strong>reward_distribution</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>)</p></li>
<li><p><strong>c</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Union</em>[<a class="reference internal" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy" title="pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy"><em>BernoulliBayesianUCBPolicy</em></a>, <a class="reference internal" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy" title="pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy"><em>GaussianBayesianUCBPolicy</em></a>]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="contextual-bandits-contextual-bandits-py">
<h2>Contextual Bandits (contextual_bandits.py)<a class="headerlink" href="#contextual-bandits-contextual-bandits-py" title="Link to this heading">¶</a></h2>
<p>Contextual Bandits extend the standard multi-armed bandit problem by incorporating contextual information. This policy adapts its arm selection based on additional features or context provided with each decision.</p>
<dl class="py class" id="module-pymab.policies.contextual_bandits">
<dt class="sig sig-object py" id="pymab.policies.contextual_bandits.ContextualBanditPolicy">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">ContextualBanditPolicy</span></span><a class="reference internal" href="_modules/pymab/policies/contextual_bandits.html#ContextualBanditPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.contextual_bandits.ContextualBanditPolicy" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">StationaryPolicyMixin</span></code>, <a class="reference internal" href="#pymab.policies.policy.Policy" title="pymab.policies.policy.Policy"><code class="xref py py-class docutils literal notranslate"><span class="pre">Policy</span></code></a></p>
<p>Implements a Contextual Bandit policy for multi-armed bandit problems.</p>
<p>This policy introduces the notion that the reward obtained at each step depends on the current context,
such as the time of the day, or whether it’s raining or not. When deciding which action to take, the agent leverages
its context to make a more informed decision. This potentially reduces the need for exploration, unlike other
policies.</p>
<p>Contextual Bandits implements a linear model to predict rewards based on the context, where the weights are updated.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_bandits</strong> – Number of bandits (actions) available.</p></li>
<li><p><strong>context_dim</strong> – Dimension of the context vector.</p></li>
<li><p><strong>context_func</strong> – Function that generates context vectors.</p></li>
<li><p><strong>optimistic_initialization</strong> – Initial Q-value for all actions. Defaults to 0.</p></li>
<li><p><strong>variance</strong> – Variance of the reward distribution. Defaults to 1.0.</p></li>
<li><p><strong>reward_distribution</strong> – Type of reward distribution. Defaults to “gaussian”.</p></li>
<li><p><strong>learning_rate</strong> – Rate at which linear coefficients are updated. Defaults to 0.1.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.contextual_bandits.ContextualBanditPolicy.context_dim">
<span class="sig-name descname"><span class="pre">context_dim</span></span><a class="headerlink" href="#pymab.policies.contextual_bandits.ContextualBanditPolicy.context_dim" title="Link to this definition">¶</a></dt>
<dd><p>Dimension of the context vector.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.contextual_bandits.ContextualBanditPolicy.theta">
<span class="sig-name descname"><span class="pre">theta</span></span><a class="headerlink" href="#pymab.policies.contextual_bandits.ContextualBanditPolicy.theta" title="Link to this definition">¶</a></dt>
<dd><p>Matrix of shape (n_bandits, context_dim) storing linear
coefficients for each bandit.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.contextual_bandits.ContextualBanditPolicy.learning_rate">
<span class="sig-name descname"><span class="pre">learning_rate</span></span><a class="headerlink" href="#pymab.policies.contextual_bandits.ContextualBanditPolicy.learning_rate" title="Link to this definition">¶</a></dt>
<dd><p>Learning rate for updating coefficients.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
</dl>
</dd></dl>

<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Theory:
Contextual Bandits extend traditional multi-armed bandits by incorporating
contextual information. The policy learns a linear mapping from context to
expected rewards for each action, enabling more informed decisions based on
the current state or environment.</p>
<p>The linear model updates follow the rule:
θ_i = θ_i + α × (r - θ_i · c) × c
where:
- θ_i is the coefficient vector for action i
- α is the learning rate
- r is the observed reward
- c is the context vector</p>
</div>
<div class="admonition-example admonition">
<p class="admonition-title">Example</p>
<p>A typical use case might be a recommendation system where the context
includes user features:
<a href="#id1"><span class="problematic" id="id2">``</span></a><a href="#id3"><span class="problematic" id="id4">`</span></a>python
def get_user_context():</p>
<blockquote>
<div><dl class="simple">
<dt>return np.array([</dt><dd><p>[user.age, user.location, user.interests],  # features for action 1
[user.age, user.location, user.interests],  # features for action 2</p>
</dd>
</dl>
<p>]).T</p>
</div></blockquote>
<dl class="simple">
<dt>policy = ContextualBanditPolicy(</dt><dd><p>n_bandits=2,
context_dim=3,
context_func=get_user_context,
learning_rate=0.1</p>
</dd>
</dl>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.contextual_bandits.ContextualBanditPolicy.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_bandits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_func</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimistic_initialization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">variance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reward_distribution</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gaussian'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/contextual_bandits.html#ContextualBanditPolicy.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.contextual_bandits.ContextualBanditPolicy.__init__" title="Link to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_bandits</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>)</p></li>
<li><p><strong>context_dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>)</p></li>
<li><p><strong>context_func</strong> (<em>Callable</em>)</p></li>
<li><p><strong>optimistic_initialization</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>)</p></li>
<li><p><strong>variance</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>)</p></li>
<li><p><strong>reward_distribution</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>)</p></li>
<li><p><strong>learning_rate</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>None</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.contextual_bandits.ContextualBanditPolicy._update">
<span class="sig-name descname"><span class="pre">_update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">chosen_action_index</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_chosen_action</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/contextual_bandits.html#ContextualBanditPolicy._update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.contextual_bandits.ContextualBanditPolicy._update" title="Link to this definition">¶</a></dt>
<dd><p>Updates the linear coefficients for the chosen action.
The coefficients are updated using the following formula:
θ_i = θ_i + α × (r - θ_i · c) × c, where c is the context and α is the learning rate.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>chosen_action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of the chosen action.</p></li>
<li><p><strong>context_chosen_action</strong> (<em>array</em>) – Context vector when the action was chosen.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The reward obtained from the chosen action.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.contextual_bandits.ContextualBanditPolicy.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/contextual_bandits.html#ContextualBanditPolicy.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.contextual_bandits.ContextualBanditPolicy.reset" title="Link to this definition">¶</a></dt>
<dd><p>Reset the policy to its initial state.</p>
<p>This method resets the base policy and reinitializes the theta matrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>None</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.contextual_bandits.ContextualBanditPolicy.select_action">
<span class="sig-name descname"><span class="pre">select_action</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">context</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/contextual_bandits.html#ContextualBanditPolicy.select_action"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.contextual_bandits.ContextualBanditPolicy.select_action" title="Link to this definition">¶</a></dt>
<dd><p>Selects the action based on the current context using a linear model, leveraging the dot product between thetas
and the current context, which represents the weighted sum of the features in the current context, and used to
estimate rewards.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>context</strong> (<em>np.array</em>) – Current context matrix of shape (context_dim, n_bandits).</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>Index of the chosen action (int)</p></li>
<li><p>Reward received (float)</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>A tuple containing</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If context dimensions don’t match expected dimensions.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pymab.policies.contextual_bandits.ContextualBanditPolicy.Q_values">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">Q_values</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#pymab.policies.contextual_bandits.ContextualBanditPolicy.Q_values" title="Link to this definition">¶</a></dt>
<dd><p>Get the true Q-values for all actions.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>List of true Q-values.</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If Q-values haven’t been set.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.contextual_bandits.ContextualBanditPolicy._get_actual_reward">
<span class="sig-name descname"><span class="pre">_get_actual_reward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_index</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.contextual_bandits.ContextualBanditPolicy._get_actual_reward" title="Link to this definition">¶</a></dt>
<dd><p>Get the actual reward for a given action.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of the chosen action.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The reward value sampled from the distribution.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.contextual_bandits.ContextualBanditPolicy._update_sliding_window">
<span class="sig-name descname"><span class="pre">_update_sliding_window</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">chosen_action_index</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.contextual_bandits.ContextualBanditPolicy._update_sliding_window" title="Link to this definition">¶</a></dt>
<dd><p>Update the sliding window of rewards for a given action.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>chosen_action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of the chosen action.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>None</em></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method maintains a fixed-size window of recent rewards
and updates the estimated reward based on this window.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.contextual_bandits.ContextualBanditPolicy.get_reward_distribution">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_reward_distribution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.contextual_bandits.ContextualBanditPolicy.get_reward_distribution" title="Link to this definition">¶</a></dt>
<dd><p>Get the reward distribution class based on the given name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Name of the reward distribution.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The corresponding reward distribution class.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If an unknown distribution name is provided.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Type</em>[<a class="reference internal" href="reward_distribution.html#pymab.reward_distribution.RewardDistribution" title="pymab.reward_distribution.RewardDistribution"><em>RewardDistribution</em></a>]</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Supported distributions are:
- ‘gaussian’: Normal distribution
- ‘bernoulli’: Binary distribution
- ‘uniform’: Uniform distribution</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.contextual_bandits.ContextualBanditPolicy.plot_distribution">
<span class="sig-name descname"><span class="pre">plot_distribution</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.contextual_bandits.ContextualBanditPolicy.plot_distribution" title="Link to this definition">¶</a></dt>
<dd><p>Plot the distributions of the expected reward for the current step.</p>
<p>This method visualizes the reward distributions for all actions, showing
both the estimated rewards and true rewards (if known).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method handles both Bernoulli and Gaussian reward distributions.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>None</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="epsilon-greedy-epsilon-greedy-py">
<h2>Epsilon Greedy (epsilon_greedy.py)<a class="headerlink" href="#epsilon-greedy-epsilon-greedy-py" title="Link to this heading">¶</a></h2>
<p>Epsilon Greedy is a simple yet effective policy that balances exploration and exploitation. It chooses the best-known arm with probability 1-ε, and explores randomly with probability ε.</p>
<dl class="py class" id="module-pymab.policies.epsilon_greedy">
<dt class="sig sig-object py" id="pymab.policies.epsilon_greedy.EpsilonGreedyPolicy">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">EpsilonGreedyPolicy</span></span><a class="reference internal" href="_modules/pymab/policies/epsilon_greedy.html#EpsilonGreedyPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.epsilon_greedy.EpsilonGreedyPolicy" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#pymab.policies.greedy.GreedyPolicy" title="pymab.policies.greedy.GreedyPolicy"><code class="xref py py-class docutils literal notranslate"><span class="pre">GreedyPolicy</span></code></a></p>
<p>Implements the Epsilon-Greedy policy for multi-armed bandit problems.</p>
<p>This policy balances exploration and exploitation by choosing the best-known action
(exploitation) with probability 1-ε, and a random action (exploration) with probability ε.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_bandits</strong> – Number of bandits (actions) available.</p></li>
<li><p><strong>optimistic_initialization</strong> – Initial Q-value for all actions. Defaults to 0.</p></li>
<li><p><strong>variance</strong> – Variance of the reward distribution. Defaults to 1.0.</p></li>
<li><p><strong>reward_distribution</strong> – Type of reward distribution. Defaults to “gaussian”.</p></li>
<li><p><strong>epsilon</strong> – Exploration rate (0 ≤ ε ≤ 1). Defaults to 0.1.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.epsilon_greedy.EpsilonGreedyPolicy.epsilon">
<span class="sig-name descname"><span class="pre">epsilon</span></span><a class="headerlink" href="#pymab.policies.epsilon_greedy.EpsilonGreedyPolicy.epsilon" title="Link to this definition">¶</a></dt>
<dd><p>Probability of choosing a random action for exploration.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
</dl>
</dd></dl>

<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Theory:
The Epsilon-Greedy strategy addresses the exploration-exploitation dilemma
by using a simple probability-based approach:</p>
<ol class="arabic simple">
<li><p>Exploration (ε probability):
- Randomly select any non-greedy action
- Helps discover potentially better actions
- Prevents getting stuck in local optima</p></li>
<li><p>Exploitation (1-ε probability):
- Select the action with highest estimated reward
- Capitalizes on current knowledge
- Maximizes immediate reward</p></li>
</ol>
<p>The value of ε controls the balance:
- Higher ε: More exploration, slower convergence
- Lower ε: More exploitation, risk of suboptimal solutions</p>
</div>
<div class="admonition-example admonition">
<p class="admonition-title">Example</p>
<p><a href="#id5"><span class="problematic" id="id6">``</span></a><a href="#id7"><span class="problematic" id="id8">`</span></a>python
# Create a policy with 10% exploration rate
policy = EpsilonGreedyPolicy(</p>
<blockquote>
<div><p>n_bandits=5,
epsilon=0.1,
reward_distribution=”gaussian”</p>
</div></blockquote>
<p>)</p>
<p># Select actions
for _ in range(100):</p>
<blockquote>
<div><p>action, reward = policy.select_action()
# Process reward…</p>
</div></blockquote>
<p><a href="#id9"><span class="problematic" id="id10">``</span></a><a href="#id11"><span class="problematic" id="id12">`</span></a></p>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.epsilon_greedy.EpsilonGreedyPolicy.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_bandits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimistic_initialization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">variance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reward_distribution</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gaussian'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/epsilon_greedy.html#EpsilonGreedyPolicy.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.epsilon_greedy.EpsilonGreedyPolicy.__init__" title="Link to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_bandits</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>)</p></li>
<li><p><strong>optimistic_initialization</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>)</p></li>
<li><p><strong>variance</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>)</p></li>
<li><p><strong>reward_distribution</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>)</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>None</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.epsilon_greedy.EpsilonGreedyPolicy.select_action">
<span class="sig-name descname"><span class="pre">select_action</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/epsilon_greedy.html#EpsilonGreedyPolicy.select_action"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.epsilon_greedy.EpsilonGreedyPolicy.select_action" title="Link to this definition">¶</a></dt>
<dd><p>Select an action based on the Epsilon-Greedy policy.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><ul class="simple">
<li><p>Index of the chosen action (int)</p></li>
<li><p>Reward received for the action (float)</p></li>
</ul>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>A tuple containing</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Implementation Details:
1. Generate random number r ∈ [0, 1]
2. If r &lt; ε:</p>
<blockquote>
<div><ul class="simple">
<li><p>Find the greedy action (highest estimated reward)</p></li>
<li><p>Remove it from possible choices</p></li>
<li><p>Select randomly from remaining actions</p></li>
</ul>
</div></blockquote>
<ol class="arabic simple" start="3">
<li><p>If r ≥ ε:
- Select the greedy action (highest estimated reward)</p></li>
</ol>
<p>This ensures that exploration explicitly avoids the greedy action,
promoting true exploration of alternative actions.</p>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pymab.policies.epsilon_greedy.EpsilonGreedyPolicy.Q_values">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">Q_values</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#pymab.policies.epsilon_greedy.EpsilonGreedyPolicy.Q_values" title="Link to this definition">¶</a></dt>
<dd><p>Get the true Q-values for all actions.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>List of true Q-values.</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If Q-values haven’t been set.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.epsilon_greedy.EpsilonGreedyPolicy._get_actual_reward">
<span class="sig-name descname"><span class="pre">_get_actual_reward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_index</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.epsilon_greedy.EpsilonGreedyPolicy._get_actual_reward" title="Link to this definition">¶</a></dt>
<dd><p>Get the actual reward for a given action.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of the chosen action.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The reward value sampled from the distribution.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.epsilon_greedy.EpsilonGreedyPolicy._update">
<span class="sig-name descname"><span class="pre">_update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">chosen_action_index</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.epsilon_greedy.EpsilonGreedyPolicy._update" title="Link to this definition">¶</a></dt>
<dd><p>Update the policy based on the chosen action and received reward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>chosen_action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of the chosen action.</p></li>
<li><p><strong>*args</strong> – Variable length argument list.</p></li>
<li><p><strong>**kwargs</strong> – Arbitrary keyword arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The reward received for the chosen action.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.epsilon_greedy.EpsilonGreedyPolicy._update_sliding_window">
<span class="sig-name descname"><span class="pre">_update_sliding_window</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">chosen_action_index</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.epsilon_greedy.EpsilonGreedyPolicy._update_sliding_window" title="Link to this definition">¶</a></dt>
<dd><p>Update the sliding window of rewards for a given action.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>chosen_action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of the chosen action.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>None</em></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method maintains a fixed-size window of recent rewards
and updates the estimated reward based on this window.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.epsilon_greedy.EpsilonGreedyPolicy.get_reward_distribution">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_reward_distribution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.epsilon_greedy.EpsilonGreedyPolicy.get_reward_distribution" title="Link to this definition">¶</a></dt>
<dd><p>Get the reward distribution class based on the given name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Name of the reward distribution.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The corresponding reward distribution class.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If an unknown distribution name is provided.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Type</em>[<a class="reference internal" href="reward_distribution.html#pymab.reward_distribution.RewardDistribution" title="pymab.reward_distribution.RewardDistribution"><em>RewardDistribution</em></a>]</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Supported distributions are:
- ‘gaussian’: Normal distribution
- ‘bernoulli’: Binary distribution
- ‘uniform’: Uniform distribution</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.epsilon_greedy.EpsilonGreedyPolicy.plot_distribution">
<span class="sig-name descname"><span class="pre">plot_distribution</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.epsilon_greedy.EpsilonGreedyPolicy.plot_distribution" title="Link to this definition">¶</a></dt>
<dd><p>Plot the distributions of the expected reward for the current step.</p>
<p>This method visualizes the reward distributions for all actions, showing
both the estimated rewards and true rewards (if known).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method handles both Bernoulli and Gaussian reward distributions.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>None</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.epsilon_greedy.EpsilonGreedyPolicy.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.epsilon_greedy.EpsilonGreedyPolicy.reset" title="Link to this definition">¶</a></dt>
<dd><p>Reset the policy to its initial state.</p>
<p>This method resets:
- Current step counter
- Total reward
- Action selection counts
- Estimated rewards
- Reward history</p>
</dd></dl>

</dd></dl>

</section>
<section id="gradient-gradient-py">
<h2>Gradient (gradient.py)<a class="headerlink" href="#gradient-gradient-py" title="Link to this heading">¶</a></h2>
<p>The Gradient policy uses a preference-based approach, updating numerical preferences for each arm based on the rewards received. It selects arms probabilistically based on these preferences.</p>
</section>
<section id="greedy-greedy-py">
<span id="module-pymab.policies.gradient"></span><h2>Greedy (greedy.py)<a class="headerlink" href="#greedy-greedy-py" title="Link to this heading">¶</a></h2>
<p>The Greedy policy always selects the arm with the highest estimated value. While simple, it can be effective in certain scenarios, especially with optimistic initialization.</p>
<dl class="py class" id="module-pymab.policies.greedy">
<dt class="sig sig-object py" id="pymab.policies.greedy.GreedyPolicy">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">GreedyPolicy</span></span><a class="reference internal" href="_modules/pymab/policies/greedy.html#GreedyPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.greedy.GreedyPolicy" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">StationaryPolicyMixin</span></code>, <a class="reference internal" href="#pymab.policies.policy.Policy" title="pymab.policies.policy.Policy"><code class="xref py py-class docutils literal notranslate"><span class="pre">Policy</span></code></a></p>
<p>Implements a Greedy policy for multi-armed bandit problems.</p>
<p>The Greedy policy always selects the action with the highest estimated reward.
It inherits from StationaryPolicyMixin and Policy, combining stationary behavior
with basic policy functionality.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_bandits</strong> – Number of bandit arms available.</p></li>
<li><p><strong>optimistic_initialization</strong> – Initial value for all action estimates. Defaults to 0.</p></li>
<li><p><strong>variance</strong> – Variance of the reward distribution. Defaults to 1.0.</p></li>
<li><p><strong>reward_distribution</strong> – Type of reward distribution. Defaults to “gaussian”.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">Inherits</span> <span class="pre">all</span> <span class="pre">attributes</span> <span class="pre">from</span> <span class="pre">Policy</span> <span class="pre">class,</span> <span class="pre">with</span> <span class="pre">no</span> <span class="pre">additional</span> <span class="pre">attributes.</span></span></dt>
<dd></dd></dl>

<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Theory:
The Greedy policy represents the pure exploitation approach to the
exploration-exploitation dilemma:</p>
<ol class="arabic simple">
<li><p>Action Selection:
- Always choose arg max_a Q(a)
- Q(a) is the estimated reward for action a
- No explicit exploration mechanism</p></li>
<li><p>Key Characteristics:
- Fast convergence when initial estimates are accurate
- Risk of suboptimal performance with poor initialization
- No guaranteed exploration of all actions</p></li>
<li><p>Optimistic Initialization:
Can be used to encourage initial exploration by setting high
initial values, causing the policy to try actions until their
estimates drop below the best-known action’s value.</p></li>
</ol>
</div>
<div class="admonition-example admonition">
<p class="admonition-title">Example</p>
<p><a href="#id13"><span class="problematic" id="id14">``</span></a><a href="#id15"><span class="problematic" id="id16">`</span></a>python
# Create a policy with optimistic initialization
policy = GreedyPolicy(</p>
<blockquote>
<div><p>n_bandits=5,
optimistic_initialization=1.0,
reward_distribution=”gaussian”</p>
</div></blockquote>
<p>)</p>
<p># Run for 100 steps
for _ in range(100):</p>
<blockquote>
<div><p>action, reward = policy.select_action()
# Process reward…</p>
</div></blockquote>
<p><a href="#id17"><span class="problematic" id="id18">``</span></a><a href="#id19"><span class="problematic" id="id20">`</span></a></p>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.greedy.GreedyPolicy.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_bandits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimistic_initialization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">variance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reward_distribution</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gaussian'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/greedy.html#GreedyPolicy.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.greedy.GreedyPolicy.__init__" title="Link to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_bandits</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>)</p></li>
<li><p><strong>optimistic_initialization</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>)</p></li>
<li><p><strong>variance</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>)</p></li>
<li><p><strong>reward_distribution</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>None</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.greedy.GreedyPolicy.select_action">
<span class="sig-name descname"><span class="pre">select_action</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/greedy.html#GreedyPolicy.select_action"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.greedy.GreedyPolicy.select_action" title="Link to this definition">¶</a></dt>
<dd><p>Selects the action with the highest estimated reward.</p>
<p>This method implements the core of the Greedy algorithm by choosing the action
with the highest estimated reward based on current knowledge.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><ul class="simple">
<li><p>Index of the chosen action (int)</p></li>
<li><p>Reward received for the action (float)</p></li>
</ul>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>A tuple containing</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The Greedy policy does not explicitly explore, which means it may miss out on
potentially better actions if the initial estimates are inaccurate. This is known
as the exploration-exploitation trade-off in reinforcement learning.</p>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pymab.policies.greedy.GreedyPolicy.Q_values">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">Q_values</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#pymab.policies.greedy.GreedyPolicy.Q_values" title="Link to this definition">¶</a></dt>
<dd><p>Get the true Q-values for all actions.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>List of true Q-values.</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If Q-values haven’t been set.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.greedy.GreedyPolicy._get_actual_reward">
<span class="sig-name descname"><span class="pre">_get_actual_reward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_index</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.greedy.GreedyPolicy._get_actual_reward" title="Link to this definition">¶</a></dt>
<dd><p>Get the actual reward for a given action.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of the chosen action.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The reward value sampled from the distribution.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.greedy.GreedyPolicy._update">
<span class="sig-name descname"><span class="pre">_update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">chosen_action_index</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.greedy.GreedyPolicy._update" title="Link to this definition">¶</a></dt>
<dd><p>Update the policy based on the chosen action and received reward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>chosen_action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of the chosen action.</p></li>
<li><p><strong>*args</strong> – Variable length argument list.</p></li>
<li><p><strong>**kwargs</strong> – Arbitrary keyword arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The reward received for the chosen action.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.greedy.GreedyPolicy._update_sliding_window">
<span class="sig-name descname"><span class="pre">_update_sliding_window</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">chosen_action_index</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.greedy.GreedyPolicy._update_sliding_window" title="Link to this definition">¶</a></dt>
<dd><p>Update the sliding window of rewards for a given action.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>chosen_action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of the chosen action.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>None</em></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method maintains a fixed-size window of recent rewards
and updates the estimated reward based on this window.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.greedy.GreedyPolicy.get_reward_distribution">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_reward_distribution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.greedy.GreedyPolicy.get_reward_distribution" title="Link to this definition">¶</a></dt>
<dd><p>Get the reward distribution class based on the given name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Name of the reward distribution.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The corresponding reward distribution class.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If an unknown distribution name is provided.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Type</em>[<a class="reference internal" href="reward_distribution.html#pymab.reward_distribution.RewardDistribution" title="pymab.reward_distribution.RewardDistribution"><em>RewardDistribution</em></a>]</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Supported distributions are:
- ‘gaussian’: Normal distribution
- ‘bernoulli’: Binary distribution
- ‘uniform’: Uniform distribution</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.greedy.GreedyPolicy.plot_distribution">
<span class="sig-name descname"><span class="pre">plot_distribution</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.greedy.GreedyPolicy.plot_distribution" title="Link to this definition">¶</a></dt>
<dd><p>Plot the distributions of the expected reward for the current step.</p>
<p>This method visualizes the reward distributions for all actions, showing
both the estimated rewards and true rewards (if known).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method handles both Bernoulli and Gaussian reward distributions.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>None</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.greedy.GreedyPolicy.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.greedy.GreedyPolicy.reset" title="Link to this definition">¶</a></dt>
<dd><p>Reset the policy to its initial state.</p>
<p>This method resets:
- Current step counter
- Total reward
- Action selection counts
- Estimated rewards
- Reward history</p>
</dd></dl>

</dd></dl>

</section>
<section id="softmax-selection-softmax-selection-py">
<h2>Softmax Selection (softmax_selection.py)<a class="headerlink" href="#softmax-selection-softmax-selection-py" title="Link to this heading">¶</a></h2>
<p>Softmax Selection chooses arms probabilistically based on their estimated values. Arms with higher estimated values have a higher probability of being selected, allowing for a degree of exploration.</p>
</section>
<section id="thompson-sampling-thompson-sampling-py">
<span id="module-pymab.policies.softmax_selection"></span><h2>Thompson Sampling (thompson_sampling.py)<a class="headerlink" href="#thompson-sampling-thompson-sampling-py" title="Link to this heading">¶</a></h2>
<p>Thompson Sampling is a probabilistic algorithm that chooses arms based on randomly drawn samples from the posterior distribution of each arm’s reward. It naturally balances exploration and exploitation.</p>
<dl class="py class" id="module-pymab.policies.thompson_sampling">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">BernoulliThompsonSamplingPolicy</span></span><a class="reference internal" href="_modules/pymab/policies/thompson_sampling.html#BernoulliThompsonSamplingPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">StationaryPolicyMixin</span></code>, <a class="reference internal" href="#pymab.policies.policy.Policy" title="pymab.policies.policy.Policy"><code class="xref py py-class docutils literal notranslate"><span class="pre">Policy</span></code></a></p>
<p>This policy is used for multi-armed bandit problems with Bernoulli-distributed rewards.
It uses the Beta distribution to model the probability of success for each action and
updates these probabilities based on observed rewards.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_bandits</strong> – Number of bandit arms available.</p></li>
<li><p><strong>optimistic_initialization</strong> – Initial value for all action estimates. Defaults to 0.</p></li>
<li><p><strong>variance</strong> – Variance of the reward distribution. Defaults to 1.0.</p></li>
<li><p><strong>reward_distribution</strong> – Must be “bernoulli”. Defaults to “bernoulli”.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.successes">
<span class="sig-name descname"><span class="pre">successes</span></span><a class="headerlink" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.successes" title="Link to this definition">¶</a></dt>
<dd><p>Number of successful outcomes for each arm.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.failures">
<span class="sig-name descname"><span class="pre">failures</span></span><a class="headerlink" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.failures" title="Link to this definition">¶</a></dt>
<dd><p>Number of failed outcomes for each arm.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.thomson_sampled">
<span class="sig-name descname"><span class="pre">thomson_sampled</span></span><a class="headerlink" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.thomson_sampled" title="Link to this definition">¶</a></dt>
<dd><p>Last sampled values from posterior distributions.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>List</em>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>]</p>
</dd>
</dl>
</dd></dl>

<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Theory:
Thompson Sampling implements Bayesian exploration by:
1. Maintaining Beta(α, β) posterior for each arm
2. α = successes + 1, β = failures + 1 (adding 1 for uniform prior)
3. Sampling θ ~ Beta(α, β) for each arm
4. Selecting arm with highest sampled θ</p>
<p>The Beta distribution is the conjugate prior for Bernoulli likelihood,
making updates simple and computationally efficient.</p>
</div>
<div class="admonition-example admonition">
<p class="admonition-title">Example</p>
<p><a href="#id21"><span class="problematic" id="id22">``</span></a><a href="#id23"><span class="problematic" id="id24">`</span></a>python
policy = BernoulliThompsonSamplingPolicy(</p>
<blockquote>
<div><p>n_bandits=5,
reward_distribution=”bernoulli”</p>
</div></blockquote>
<p>)</p>
<p># Run for 1000 steps
for _ in range(1000):</p>
<blockquote>
<div><p>action, reward = policy.select_action()
# Process binary reward (0 or 1)…</p>
</div></blockquote>
<p><a href="#id25"><span class="problematic" id="id26">``</span></a><a href="#id27"><span class="problematic" id="id28">`</span></a></p>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.n_bandits">
<span class="sig-name descname"><span class="pre">n_bandits</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></em><a class="headerlink" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.n_bandits" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.optimistic_initialization">
<span class="sig-name descname"><span class="pre">optimistic_initialization</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></em><a class="headerlink" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.optimistic_initialization" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.current_step">
<span class="sig-name descname"><span class="pre">current_step</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></em><a class="headerlink" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.current_step" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.total_reward">
<span class="sig-name descname"><span class="pre">total_reward</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></em><a class="headerlink" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.total_reward" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.times_selected">
<span class="sig-name descname"><span class="pre">times_selected</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">np.array</span></em><a class="headerlink" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.times_selected" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.actions_estimated_reward">
<span class="sig-name descname"><span class="pre">actions_estimated_reward</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">np.array</span></em><a class="headerlink" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.actions_estimated_reward" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.variance">
<span class="sig-name descname"><span class="pre">variance</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></em><a class="headerlink" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.variance" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.reward_distribution">
<span class="sig-name descname"><span class="pre">reward_distribution</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="reward_distribution.html#pymab.reward_distribution.RewardDistribution" title="pymab.reward_distribution.RewardDistribution"><span class="pre">RewardDistribution</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.reward_distribution" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.rewards_history">
<span class="sig-name descname"><span class="pre">rewards_history</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.rewards_history" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_bandits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimistic_initialization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">variance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reward_distribution</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gaussian'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/thompson_sampling.html#BernoulliThompsonSamplingPolicy.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.__init__" title="Link to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_bandits</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>)</p></li>
<li><p><strong>optimistic_initialization</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>)</p></li>
<li><p><strong>variance</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>)</p></li>
<li><p><strong>reward_distribution</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>None</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="id0">
<span class="sig-name descname"><span class="pre">successes</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">np.array</span></em><a class="headerlink" href="#id0" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="id29">
<span class="sig-name descname"><span class="pre">failures</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">np.array</span></em><a class="headerlink" href="#id29" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy._update">
<span class="sig-name descname"><span class="pre">_update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">chosen_action_index</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/thompson_sampling.html#BernoulliThompsonSamplingPolicy._update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy._update" title="Link to this definition">¶</a></dt>
<dd><p>Updates the parameters successes and failures used in the Beta distribution, according to the reward
obtained.
The Bernoulli distribution is conjugate to the Beta distribution, meaning that if the prior distribution of the
probability of success is a Beta distribution, then the posterior distribution after observing data is also a
Beta distribution. This makes the Bayesian updating process straightforward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>chosen_action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of the chosen action.</p></li>
<li><p><strong>*args</strong> – Variable length argument list.</p></li>
<li><p><strong>**kwargs</strong> – Arbitrary keyword arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The observed reward (0 or 1).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Uses conjugate prior property of Beta-Bernoulli:
- Success (reward = 1): Increment α
- Failure (reward = 0): Increment β</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.select_action">
<span class="sig-name descname"><span class="pre">select_action</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/thompson_sampling.html#BernoulliThompsonSamplingPolicy.select_action"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.select_action" title="Link to this definition">¶</a></dt>
<dd><p>Select action using Thompson Sampling.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><ul class="simple">
<li><p>Index of the chosen action (int)</p></li>
<li><p>Reward received for the action (float)</p></li>
</ul>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>A tuple containing</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Implementation:
1. Sample θ ~ Beta(α, β) for each arm
2. Select arm with highest θ
3. Observe reward and update parameters</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.plot_distribution">
<span class="sig-name descname"><span class="pre">plot_distribution</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/thompson_sampling.html#BernoulliThompsonSamplingPolicy.plot_distribution"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.plot_distribution" title="Link to this definition">¶</a></dt>
<dd><p>Plots the distributions of the expected reward for the current step.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>None</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.Q_values">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">Q_values</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.Q_values" title="Link to this definition">¶</a></dt>
<dd><p>Get the true Q-values for all actions.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>List of true Q-values.</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If Q-values haven’t been set.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy._get_actual_reward">
<span class="sig-name descname"><span class="pre">_get_actual_reward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_index</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy._get_actual_reward" title="Link to this definition">¶</a></dt>
<dd><p>Get the actual reward for a given action.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of the chosen action.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The reward value sampled from the distribution.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy._update_sliding_window">
<span class="sig-name descname"><span class="pre">_update_sliding_window</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">chosen_action_index</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy._update_sliding_window" title="Link to this definition">¶</a></dt>
<dd><p>Update the sliding window of rewards for a given action.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>chosen_action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of the chosen action.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>None</em></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method maintains a fixed-size window of recent rewards
and updates the estimated reward based on this window.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.get_reward_distribution">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_reward_distribution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.get_reward_distribution" title="Link to this definition">¶</a></dt>
<dd><p>Get the reward distribution class based on the given name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Name of the reward distribution.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The corresponding reward distribution class.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If an unknown distribution name is provided.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Type</em>[<a class="reference internal" href="reward_distribution.html#pymab.reward_distribution.RewardDistribution" title="pymab.reward_distribution.RewardDistribution"><em>RewardDistribution</em></a>]</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Supported distributions are:
- ‘gaussian’: Normal distribution
- ‘bernoulli’: Binary distribution
- ‘uniform’: Uniform distribution</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.reset" title="Link to this definition">¶</a></dt>
<dd><p>Reset the policy to its initial state.</p>
<p>This method resets:
- Current step counter
- Total reward
- Action selection counts
- Estimated rewards
- Reward history</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">GaussianThompsonSamplingPolicy</span></span><a class="reference internal" href="_modules/pymab/policies/thompson_sampling.html#GaussianThompsonSamplingPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">StationaryPolicyMixin</span></code>, <a class="reference internal" href="#pymab.policies.policy.Policy" title="pymab.policies.policy.Policy"><code class="xref py py-class docutils literal notranslate"><span class="pre">Policy</span></code></a></p>
<p>This policy is used for multi-armed bandit problems with Gaussian-distributed rewards.
It models the mean reward for each action using a Gaussian distribution and updates
these means based on observed rewards.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_bandits</strong> – Number of bandit arms available.</p></li>
<li><p><strong>optimistic_initialization</strong> – Initial value for all action estimates. Defaults to 0.</p></li>
<li><p><strong>variance</strong> – Variance of the reward distribution. Defaults to 1.0.</p></li>
<li><p><strong>reward_distribution</strong> – Must be “gaussian”. Defaults to “gaussian”.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.means">
<span class="sig-name descname"><span class="pre">means</span></span><a class="headerlink" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.means" title="Link to this definition">¶</a></dt>
<dd><p>Posterior mean for each arm.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.precisions">
<span class="sig-name descname"><span class="pre">precisions</span></span><a class="headerlink" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.precisions" title="Link to this definition">¶</a></dt>
<dd><p>Posterior precision (1/variance) for each arm.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Theory:
The policy maintains a Normal distribution for each arm’s mean reward:
1. Uses conjugate Normal prior with known variance
2. Updates posterior mean and precision after each observation
3. Samples from posterior and selects highest sample</p>
<p>The Normal distribution is conjugate to itself with known variance,
allowing closed-form Bayesian updates.</p>
</div>
<div class="admonition-example admonition">
<p class="admonition-title">Example</p>
<p><a href="#id30"><span class="problematic" id="id31">``</span></a><a href="#id32"><span class="problematic" id="id33">`</span></a>python
policy = GaussianThompsonSamplingPolicy(</p>
<blockquote>
<div><p>n_bandits=5,
variance=1.0,
reward_distribution=”gaussian”</p>
</div></blockquote>
<p>)</p>
<p># Run for 1000 steps
for _ in range(1000):</p>
<blockquote>
<div><p>action, reward = policy.select_action()
# Process continuous reward…</p>
</div></blockquote>
<p><a href="#id34"><span class="problematic" id="id35">``</span></a><a href="#id36"><span class="problematic" id="id37">`</span></a></p>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.n_bandits">
<span class="sig-name descname"><span class="pre">n_bandits</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></em><a class="headerlink" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.n_bandits" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.optimistic_initialization">
<span class="sig-name descname"><span class="pre">optimistic_initialization</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></em><a class="headerlink" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.optimistic_initialization" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.current_step">
<span class="sig-name descname"><span class="pre">current_step</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></em><a class="headerlink" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.current_step" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.total_reward">
<span class="sig-name descname"><span class="pre">total_reward</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></em><a class="headerlink" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.total_reward" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.times_selected">
<span class="sig-name descname"><span class="pre">times_selected</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">array</span></em><a class="headerlink" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.times_selected" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.actions_estimated_reward">
<span class="sig-name descname"><span class="pre">actions_estimated_reward</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">array</span></em><a class="headerlink" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.actions_estimated_reward" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.variance">
<span class="sig-name descname"><span class="pre">variance</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></em><a class="headerlink" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.variance" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.reward_distribution">
<span class="sig-name descname"><span class="pre">reward_distribution</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="reward_distribution.html#pymab.reward_distribution.RewardDistribution" title="pymab.reward_distribution.RewardDistribution"><span class="pre">RewardDistribution</span></a></em><a class="headerlink" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.reward_distribution" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_bandits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimistic_initialization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">variance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reward_distribution</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gaussian'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/thompson_sampling.html#GaussianThompsonSamplingPolicy.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.__init__" title="Link to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_bandits</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>)</p></li>
<li><p><strong>optimistic_initialization</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>)</p></li>
<li><p><strong>variance</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>)</p></li>
<li><p><strong>reward_distribution</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>None</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="id38">
<span class="sig-name descname"><span class="pre">means</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">array</span></em><a class="headerlink" href="#id38" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="id39">
<span class="sig-name descname"><span class="pre">precisions</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">array</span></em><a class="headerlink" href="#id39" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy._update">
<span class="sig-name descname"><span class="pre">_update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">chosen_action_index</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/thompson_sampling.html#GaussianThompsonSamplingPolicy._update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy._update" title="Link to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Updates the Guassian prior distribution according to the observed reward. The conjugate prior for the mean of a Gaussian distribution with known variance is also Gaussian.</dt><dd><p>The posterior distribution of the mean given Gaussian observations remains Gaussian, which allows for a Bayesian update, but it involves maintaining and updating the mean and variance parameters.</p>
</dd>
</dl>
<p>The means and precisions (tau) arrays maintain the posterior mean and precision (inverse of variance) for each action. These are updated after each observed reward using Bayesian inference.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>chosen_action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of the chosen action.</p></li>
<li><p><strong>*args</strong> – Variable length argument list.</p></li>
<li><p><strong>**kwargs</strong> – Arbitrary keyword arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The observed reward (continuous value).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Implementation:
1. Compute posterior mean using precision-weighted average
2. Update precision by adding 1 (for unit variance likelihood)
3. Store updated parameters for chosen arm</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.select_action">
<span class="sig-name descname"><span class="pre">select_action</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/thompson_sampling.html#GaussianThompsonSamplingPolicy.select_action"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.select_action" title="Link to this definition">¶</a></dt>
<dd><p>Select action using Thompson Sampling.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><ul class="simple">
<li><p>Index of the chosen action (int)</p></li>
<li><p>Reward received for the action (float)</p></li>
</ul>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>A tuple containing</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Implementation:
1. Sample μ ~ N(mean, 1/precision) for each arm
2. Select arm with highest sampled μ
3. Observe reward and update parameters</p>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.Q_values">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">Q_values</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.Q_values" title="Link to this definition">¶</a></dt>
<dd><p>Get the true Q-values for all actions.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>List of true Q-values.</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If Q-values haven’t been set.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy._get_actual_reward">
<span class="sig-name descname"><span class="pre">_get_actual_reward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_index</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy._get_actual_reward" title="Link to this definition">¶</a></dt>
<dd><p>Get the actual reward for a given action.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of the chosen action.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The reward value sampled from the distribution.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy._update_sliding_window">
<span class="sig-name descname"><span class="pre">_update_sliding_window</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">chosen_action_index</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy._update_sliding_window" title="Link to this definition">¶</a></dt>
<dd><p>Update the sliding window of rewards for a given action.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>chosen_action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of the chosen action.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>None</em></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method maintains a fixed-size window of recent rewards
and updates the estimated reward based on this window.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.get_reward_distribution">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_reward_distribution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.get_reward_distribution" title="Link to this definition">¶</a></dt>
<dd><p>Get the reward distribution class based on the given name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Name of the reward distribution.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The corresponding reward distribution class.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If an unknown distribution name is provided.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Type</em>[<a class="reference internal" href="reward_distribution.html#pymab.reward_distribution.RewardDistribution" title="pymab.reward_distribution.RewardDistribution"><em>RewardDistribution</em></a>]</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Supported distributions are:
- ‘gaussian’: Normal distribution
- ‘bernoulli’: Binary distribution
- ‘uniform’: Uniform distribution</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.reset" title="Link to this definition">¶</a></dt>
<dd><p>Reset the policy to its initial state.</p>
<p>This method resets:
- Current step counter
- Total reward
- Action selection counts
- Estimated rewards
- Reward history</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.plot_distribution">
<span class="sig-name descname"><span class="pre">plot_distribution</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/thompson_sampling.html#GaussianThompsonSamplingPolicy.plot_distribution"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.plot_distribution" title="Link to this definition">¶</a></dt>
<dd><p>Plots the distributions of the expected reward for the current step.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>None</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.ThompsonSamplingPolicy">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">ThompsonSamplingPolicy</span></span><a class="reference internal" href="_modules/pymab/policies/thompson_sampling.html#ThompsonSamplingPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.thompson_sampling.ThompsonSamplingPolicy" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Factory class for creating Thompson Sampling policies.</p>
<p>This class serves as a factory to create the appropriate Thompson Sampling policy
based on the reward distribution type (Bernoulli or Gaussian).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_bandits</strong> – Number of bandit arms available.</p></li>
<li><p><strong>optimistic_initialization</strong> – Initial value for all action estimates. Defaults to 0.</p></li>
<li><p><strong>variance</strong> – Variance of the reward distribution. Defaults to 1.0.</p></li>
<li><p><strong>reward_distribution</strong> – Type of reward distribution (“bernoulli” or “gaussian”).
Defaults to “gaussian”.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The appropriate Thompson Sampling policy instance.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If an unsupported reward distribution is specified.</p>
</dd>
</dl>
<div class="admonition-example admonition">
<p class="admonition-title">Example</p>
<p><a href="#id40"><span class="problematic" id="id41">``</span></a><a href="#id42"><span class="problematic" id="id43">`</span></a>python
# Create a Bernoulli policy
policy = ThompsonSamplingPolicy(</p>
<blockquote>
<div><p>n_bandits=5,
reward_distribution=”bernoulli”</p>
</div></blockquote>
<p>)</p>
<p># Create a Gaussian policy
policy = ThompsonSamplingPolicy(</p>
<blockquote>
<div><p>n_bandits=5,
reward_distribution=”gaussian”</p>
</div></blockquote>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.thompson_sampling.ThompsonSamplingPolicy.__new__">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">__new__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cls</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_bandits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimistic_initialization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">variance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reward_distribution</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gaussian'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/thompson_sampling.html#ThompsonSamplingPolicy.__new__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.thompson_sampling.ThompsonSamplingPolicy.__new__" title="Link to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_bandits</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>)</p></li>
<li><p><strong>optimistic_initialization</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>)</p></li>
<li><p><strong>variance</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>)</p></li>
<li><p><strong>reward_distribution</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Union</em>[<a class="reference internal" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy" title="pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy"><em>BernoulliThompsonSamplingPolicy</em></a>, <a class="reference internal" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy" title="pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy"><em>GaussianThompsonSamplingPolicy</em></a>]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="ucb-ucb-py">
<h2>UCB (ucb.py)<a class="headerlink" href="#ucb-ucb-py" title="Link to this heading">¶</a></h2>
<p>Upper Confidence Bound (UCB) is a deterministic policy that balances exploration and exploitation by selecting the arm with the highest upper confidence bound. It’s known for its strong theoretical guarantees.</p>
<dl class="py class" id="module-pymab.policies.ucb">
<dt class="sig sig-object py" id="pymab.policies.ucb.UCBPolicy">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">UCBPolicy</span></span><a class="reference internal" href="_modules/pymab/policies/ucb.html#UCBPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.ucb.UCBPolicy" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">StationaryPolicyMixin</span></code>, <a class="reference internal" href="#pymab.policies.policy.Policy" title="pymab.policies.policy.Policy"><code class="xref py py-class docutils literal notranslate"><span class="pre">Policy</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/abc.html#abc.ABC" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.UCBPolicy.n_bandits">
<span class="sig-name descname"><span class="pre">n_bandits</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></em><a class="headerlink" href="#pymab.policies.ucb.UCBPolicy.n_bandits" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.UCBPolicy.optimistic_initialization">
<span class="sig-name descname"><span class="pre">optimistic_initialization</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></em><a class="headerlink" href="#pymab.policies.ucb.UCBPolicy.optimistic_initialization" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.UCBPolicy.current_step">
<span class="sig-name descname"><span class="pre">current_step</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></em><a class="headerlink" href="#pymab.policies.ucb.UCBPolicy.current_step" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.UCBPolicy.total_reward">
<span class="sig-name descname"><span class="pre">total_reward</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></em><a class="headerlink" href="#pymab.policies.ucb.UCBPolicy.total_reward" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.UCBPolicy.times_selected">
<span class="sig-name descname"><span class="pre">times_selected</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">np.array</span></em><a class="headerlink" href="#pymab.policies.ucb.UCBPolicy.times_selected" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.UCBPolicy.actions_estimated_reward">
<span class="sig-name descname"><span class="pre">actions_estimated_reward</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">np.array</span></em><a class="headerlink" href="#pymab.policies.ucb.UCBPolicy.actions_estimated_reward" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.UCBPolicy.variance">
<span class="sig-name descname"><span class="pre">variance</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></em><a class="headerlink" href="#pymab.policies.ucb.UCBPolicy.variance" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.UCBPolicy.reward_distribution">
<span class="sig-name descname"><span class="pre">reward_distribution</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="reward_distribution.html#pymab.reward_distribution.RewardDistribution" title="pymab.reward_distribution.RewardDistribution"><span class="pre">RewardDistribution</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#pymab.policies.ucb.UCBPolicy.reward_distribution" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.UCBPolicy.rewards_history">
<span class="sig-name descname"><span class="pre">rewards_history</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#pymab.policies.ucb.UCBPolicy.rewards_history" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.ucb.UCBPolicy.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_bandits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimistic_initialization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">variance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reward_distribution</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gaussian'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/ucb.html#UCBPolicy.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.ucb.UCBPolicy.__init__" title="Link to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_bandits</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>)</p></li>
<li><p><strong>optimistic_initialization</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>)</p></li>
<li><p><strong>variance</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>)</p></li>
<li><p><strong>reward_distribution</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>)</p></li>
<li><p><strong>c</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>None</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.UCBPolicy.c">
<span class="sig-name descname"><span class="pre">c</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></em><a class="headerlink" href="#pymab.policies.ucb.UCBPolicy.c" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.ucb.UCBPolicy._calculate_confidence_interval">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">_calculate_confidence_interval</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_index</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/ucb.html#UCBPolicy._calculate_confidence_interval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.ucb.UCBPolicy._calculate_confidence_interval" title="Link to this definition">¶</a></dt>
<dd><p>Calculate the confidence interval for a given action.</p>
<p>This method is abstract and should be implemented by subclasses to define
the specific confidence interval calculation for each UCB variant.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – The index of the action to calculate the confidence interval for.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The calculated confidence interval.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.ucb.UCBPolicy._get_ucb_value">
<span class="sig-name descname"><span class="pre">_get_ucb_value</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_index</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/ucb.html#UCBPolicy._get_ucb_value"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.ucb.UCBPolicy._get_ucb_value" title="Link to this definition">¶</a></dt>
<dd><p>Calculate the Upper Confidence Bound (UCB) value for a given action.</p>
<p>This method implements the core UCB algorithm by combining the estimated reward
with the confidence interval. It handles the case of unselected actions by
returning infinity, ensuring exploration of all actions initially.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – The index of the action to calculate the UCB value for.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The calculated UCB value, or infinity for unselected actions.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
<dt class="field-even">Theory<span class="colon">:</span></dt>
<dd class="field-even"><p>UCB = Q(a) + U(a), where Q(a) is the estimated reward and U(a) is the confidence interval.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.ucb.UCBPolicy.select_action">
<span class="sig-name descname"><span class="pre">select_action</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/ucb.html#UCBPolicy.select_action"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.ucb.UCBPolicy.select_action" title="Link to this definition">¶</a></dt>
<dd><p>Select the next action based on the UCB algorithm.</p>
<p>This method implements the action selection strategy of UCB:
1. Initially, it selects each action once to gather initial estimates.
2. After that, it chooses the action with the highest UCB value.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A tuple containing the index of the chosen action and the reward obtained from taking that action.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tuple</em>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>]</p>
</dd>
</dl>
<p>Examples:
Here’s how to use the <cite>select_action</cite> method:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">policy</span> <span class="o">=</span> <span class="n">UCBPolicy</span><span class="p">(</span><span class="n">n_bandits</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">action</span><span class="p">,</span> <span class="n">reward</span> <span class="o">=</span> <span class="n">policy</span><span class="o">.</span><span class="n">select_action</span><span class="p">()</span>
    <span class="c1"># Use the action and reward as needed</span>
</pre></div>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pymab.policies.ucb.UCBPolicy.Q_values">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">Q_values</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#pymab.policies.ucb.UCBPolicy.Q_values" title="Link to this definition">¶</a></dt>
<dd><p>Get the true Q-values for all actions.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>List of true Q-values.</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If Q-values haven’t been set.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.ucb.UCBPolicy._get_actual_reward">
<span class="sig-name descname"><span class="pre">_get_actual_reward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_index</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.ucb.UCBPolicy._get_actual_reward" title="Link to this definition">¶</a></dt>
<dd><p>Get the actual reward for a given action.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of the chosen action.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The reward value sampled from the distribution.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.ucb.UCBPolicy._update">
<span class="sig-name descname"><span class="pre">_update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">chosen_action_index</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.ucb.UCBPolicy._update" title="Link to this definition">¶</a></dt>
<dd><p>Update the policy based on the chosen action and received reward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>chosen_action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of the chosen action.</p></li>
<li><p><strong>*args</strong> – Variable length argument list.</p></li>
<li><p><strong>**kwargs</strong> – Arbitrary keyword arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The reward received for the chosen action.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.ucb.UCBPolicy._update_sliding_window">
<span class="sig-name descname"><span class="pre">_update_sliding_window</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">chosen_action_index</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.ucb.UCBPolicy._update_sliding_window" title="Link to this definition">¶</a></dt>
<dd><p>Update the sliding window of rewards for a given action.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>chosen_action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of the chosen action.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>None</em></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method maintains a fixed-size window of recent rewards
and updates the estimated reward based on this window.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.ucb.UCBPolicy.get_reward_distribution">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_reward_distribution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.ucb.UCBPolicy.get_reward_distribution" title="Link to this definition">¶</a></dt>
<dd><p>Get the reward distribution class based on the given name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Name of the reward distribution.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The corresponding reward distribution class.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If an unknown distribution name is provided.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Type</em>[<a class="reference internal" href="reward_distribution.html#pymab.reward_distribution.RewardDistribution" title="pymab.reward_distribution.RewardDistribution"><em>RewardDistribution</em></a>]</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Supported distributions are:
- ‘gaussian’: Normal distribution
- ‘bernoulli’: Binary distribution
- ‘uniform’: Uniform distribution</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.ucb.UCBPolicy.plot_distribution">
<span class="sig-name descname"><span class="pre">plot_distribution</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.ucb.UCBPolicy.plot_distribution" title="Link to this definition">¶</a></dt>
<dd><p>Plot the distributions of the expected reward for the current step.</p>
<p>This method visualizes the reward distributions for all actions, showing
both the estimated rewards and true rewards (if known).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method handles both Bernoulli and Gaussian reward distributions.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>None</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.ucb.UCBPolicy.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.ucb.UCBPolicy.reset" title="Link to this definition">¶</a></dt>
<dd><p>Reset the policy to its initial state.</p>
<p>This method resets:
- Current step counter
- Total reward
- Action selection counts
- Estimated rewards
- Reward history</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pymab.policies.ucb.StationaryUCBPolicy">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">StationaryUCBPolicy</span></span><a class="reference internal" href="_modules/pymab/policies/ucb.html#StationaryUCBPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.ucb.StationaryUCBPolicy" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#pymab.policies.ucb.UCBPolicy" title="pymab.policies.ucb.UCBPolicy"><code class="xref py py-class docutils literal notranslate"><span class="pre">UCBPolicy</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.StationaryUCBPolicy.n_bandits">
<span class="sig-name descname"><span class="pre">n_bandits</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></em><a class="headerlink" href="#pymab.policies.ucb.StationaryUCBPolicy.n_bandits" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.StationaryUCBPolicy.optimistic_initialization">
<span class="sig-name descname"><span class="pre">optimistic_initialization</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></em><a class="headerlink" href="#pymab.policies.ucb.StationaryUCBPolicy.optimistic_initialization" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.StationaryUCBPolicy.current_step">
<span class="sig-name descname"><span class="pre">current_step</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></em><a class="headerlink" href="#pymab.policies.ucb.StationaryUCBPolicy.current_step" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.StationaryUCBPolicy.total_reward">
<span class="sig-name descname"><span class="pre">total_reward</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></em><a class="headerlink" href="#pymab.policies.ucb.StationaryUCBPolicy.total_reward" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.StationaryUCBPolicy.times_selected">
<span class="sig-name descname"><span class="pre">times_selected</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">np.array</span></em><a class="headerlink" href="#pymab.policies.ucb.StationaryUCBPolicy.times_selected" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.StationaryUCBPolicy.actions_estimated_reward">
<span class="sig-name descname"><span class="pre">actions_estimated_reward</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">np.array</span></em><a class="headerlink" href="#pymab.policies.ucb.StationaryUCBPolicy.actions_estimated_reward" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.StationaryUCBPolicy.variance">
<span class="sig-name descname"><span class="pre">variance</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></em><a class="headerlink" href="#pymab.policies.ucb.StationaryUCBPolicy.variance" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.StationaryUCBPolicy.reward_distribution">
<span class="sig-name descname"><span class="pre">reward_distribution</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="reward_distribution.html#pymab.reward_distribution.RewardDistribution" title="pymab.reward_distribution.RewardDistribution"><span class="pre">RewardDistribution</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#pymab.policies.ucb.StationaryUCBPolicy.reward_distribution" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.StationaryUCBPolicy.c">
<span class="sig-name descname"><span class="pre">c</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></em><a class="headerlink" href="#pymab.policies.ucb.StationaryUCBPolicy.c" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.ucb.StationaryUCBPolicy._calculate_confidence_interval">
<span class="sig-name descname"><span class="pre">_calculate_confidence_interval</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_index</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/ucb.html#StationaryUCBPolicy._calculate_confidence_interval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.ucb.StationaryUCBPolicy._calculate_confidence_interval" title="Link to this definition">¶</a></dt>
<dd><p>Calculate the confidence interval for the stationary UCB algorithm.</p>
<p>This method implements the standard UCB1 confidence interval calculation,
which assumes a stationary environment (i.e., reward distributions do not change over time).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – The index of the action to calculate the confidence interval for.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The calculated confidence interval.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
<dt class="field-even">Theory<span class="colon">:</span></dt>
<dd class="field-even"><p>The confidence interval is calculated as sqrt((c * log(t)) / n_a),
where c is the exploration parameter, t is the current time step,
and n_a is the number of times the action has been selected.</p>
</dd>
<dt class="field-odd">Optimization<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>Uses math.sqrt and math.log for efficient calculation.</p></li>
<li><p>Adds 1 to current_step to avoid log(0) in the first step.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pymab.policies.ucb.StationaryUCBPolicy.Q_values">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">Q_values</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#pymab.policies.ucb.StationaryUCBPolicy.Q_values" title="Link to this definition">¶</a></dt>
<dd><p>Get the true Q-values for all actions.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>List of true Q-values.</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If Q-values haven’t been set.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.ucb.StationaryUCBPolicy.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_bandits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimistic_initialization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">variance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reward_distribution</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gaussian'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.ucb.StationaryUCBPolicy.__init__" title="Link to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_bandits</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>)</p></li>
<li><p><strong>optimistic_initialization</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>)</p></li>
<li><p><strong>variance</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>)</p></li>
<li><p><strong>reward_distribution</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>)</p></li>
<li><p><strong>c</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>None</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.ucb.StationaryUCBPolicy._get_actual_reward">
<span class="sig-name descname"><span class="pre">_get_actual_reward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_index</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.ucb.StationaryUCBPolicy._get_actual_reward" title="Link to this definition">¶</a></dt>
<dd><p>Get the actual reward for a given action.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of the chosen action.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The reward value sampled from the distribution.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.ucb.StationaryUCBPolicy._get_ucb_value">
<span class="sig-name descname"><span class="pre">_get_ucb_value</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_index</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.ucb.StationaryUCBPolicy._get_ucb_value" title="Link to this definition">¶</a></dt>
<dd><p>Calculate the Upper Confidence Bound (UCB) value for a given action.</p>
<p>This method implements the core UCB algorithm by combining the estimated reward
with the confidence interval. It handles the case of unselected actions by
returning infinity, ensuring exploration of all actions initially.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – The index of the action to calculate the UCB value for.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The calculated UCB value, or infinity for unselected actions.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
<dt class="field-even">Theory<span class="colon">:</span></dt>
<dd class="field-even"><p>UCB = Q(a) + U(a), where Q(a) is the estimated reward and U(a) is the confidence interval.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.ucb.StationaryUCBPolicy._update">
<span class="sig-name descname"><span class="pre">_update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">chosen_action_index</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.ucb.StationaryUCBPolicy._update" title="Link to this definition">¶</a></dt>
<dd><p>Update the policy based on the chosen action and received reward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>chosen_action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of the chosen action.</p></li>
<li><p><strong>*args</strong> – Variable length argument list.</p></li>
<li><p><strong>**kwargs</strong> – Arbitrary keyword arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The reward received for the chosen action.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.ucb.StationaryUCBPolicy._update_sliding_window">
<span class="sig-name descname"><span class="pre">_update_sliding_window</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">chosen_action_index</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.ucb.StationaryUCBPolicy._update_sliding_window" title="Link to this definition">¶</a></dt>
<dd><p>Update the sliding window of rewards for a given action.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>chosen_action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of the chosen action.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>None</em></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method maintains a fixed-size window of recent rewards
and updates the estimated reward based on this window.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.ucb.StationaryUCBPolicy.get_reward_distribution">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_reward_distribution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.ucb.StationaryUCBPolicy.get_reward_distribution" title="Link to this definition">¶</a></dt>
<dd><p>Get the reward distribution class based on the given name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Name of the reward distribution.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The corresponding reward distribution class.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If an unknown distribution name is provided.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Type</em>[<a class="reference internal" href="reward_distribution.html#pymab.reward_distribution.RewardDistribution" title="pymab.reward_distribution.RewardDistribution"><em>RewardDistribution</em></a>]</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Supported distributions are:
- ‘gaussian’: Normal distribution
- ‘bernoulli’: Binary distribution
- ‘uniform’: Uniform distribution</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.ucb.StationaryUCBPolicy.plot_distribution">
<span class="sig-name descname"><span class="pre">plot_distribution</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.ucb.StationaryUCBPolicy.plot_distribution" title="Link to this definition">¶</a></dt>
<dd><p>Plot the distributions of the expected reward for the current step.</p>
<p>This method visualizes the reward distributions for all actions, showing
both the estimated rewards and true rewards (if known).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method handles both Bernoulli and Gaussian reward distributions.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>None</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.ucb.StationaryUCBPolicy.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.ucb.StationaryUCBPolicy.reset" title="Link to this definition">¶</a></dt>
<dd><p>Reset the policy to its initial state.</p>
<p>This method resets:
- Current step counter
- Total reward
- Action selection counts
- Estimated rewards
- Reward history</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.ucb.StationaryUCBPolicy.select_action">
<span class="sig-name descname"><span class="pre">select_action</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.ucb.StationaryUCBPolicy.select_action" title="Link to this definition">¶</a></dt>
<dd><p>Select the next action based on the UCB algorithm.</p>
<p>This method implements the action selection strategy of UCB:
1. Initially, it selects each action once to gather initial estimates.
2. After that, it chooses the action with the highest UCB value.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A tuple containing the index of the chosen action and the reward obtained from taking that action.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tuple</em>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>]</p>
</dd>
</dl>
<p>Examples:
Here’s how to use the <cite>select_action</cite> method:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">policy</span> <span class="o">=</span> <span class="n">UCBPolicy</span><span class="p">(</span><span class="n">n_bandits</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">action</span><span class="p">,</span> <span class="n">reward</span> <span class="o">=</span> <span class="n">policy</span><span class="o">.</span><span class="n">select_action</span><span class="p">()</span>
    <span class="c1"># Use the action and reward as needed</span>
</pre></div>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.StationaryUCBPolicy.rewards_history">
<span class="sig-name descname"><span class="pre">rewards_history</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#pymab.policies.ucb.StationaryUCBPolicy.rewards_history" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pymab.policies.ucb.SlidingWindowUCBPolicy">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">SlidingWindowUCBPolicy</span></span><a class="reference internal" href="_modules/pymab/policies/ucb.html#SlidingWindowUCBPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.ucb.SlidingWindowUCBPolicy" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">SlidingWindowMixin</span></code>, <a class="reference internal" href="#pymab.policies.ucb.UCBPolicy" title="pymab.policies.ucb.UCBPolicy"><code class="xref py py-class docutils literal notranslate"><span class="pre">UCBPolicy</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.SlidingWindowUCBPolicy.n_bandits">
<span class="sig-name descname"><span class="pre">n_bandits</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></em><a class="headerlink" href="#pymab.policies.ucb.SlidingWindowUCBPolicy.n_bandits" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.SlidingWindowUCBPolicy.optimistic_initialization">
<span class="sig-name descname"><span class="pre">optimistic_initialization</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></em><a class="headerlink" href="#pymab.policies.ucb.SlidingWindowUCBPolicy.optimistic_initialization" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.SlidingWindowUCBPolicy.current_step">
<span class="sig-name descname"><span class="pre">current_step</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></em><a class="headerlink" href="#pymab.policies.ucb.SlidingWindowUCBPolicy.current_step" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.SlidingWindowUCBPolicy.total_reward">
<span class="sig-name descname"><span class="pre">total_reward</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></em><a class="headerlink" href="#pymab.policies.ucb.SlidingWindowUCBPolicy.total_reward" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.SlidingWindowUCBPolicy.times_selected">
<span class="sig-name descname"><span class="pre">times_selected</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">np.array</span></em><a class="headerlink" href="#pymab.policies.ucb.SlidingWindowUCBPolicy.times_selected" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.SlidingWindowUCBPolicy.actions_estimated_reward">
<span class="sig-name descname"><span class="pre">actions_estimated_reward</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">np.array</span></em><a class="headerlink" href="#pymab.policies.ucb.SlidingWindowUCBPolicy.actions_estimated_reward" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.SlidingWindowUCBPolicy.variance">
<span class="sig-name descname"><span class="pre">variance</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></em><a class="headerlink" href="#pymab.policies.ucb.SlidingWindowUCBPolicy.variance" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.SlidingWindowUCBPolicy.reward_distribution">
<span class="sig-name descname"><span class="pre">reward_distribution</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="reward_distribution.html#pymab.reward_distribution.RewardDistribution" title="pymab.reward_distribution.RewardDistribution"><span class="pre">RewardDistribution</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#pymab.policies.ucb.SlidingWindowUCBPolicy.reward_distribution" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.SlidingWindowUCBPolicy.c">
<span class="sig-name descname"><span class="pre">c</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></em><a class="headerlink" href="#pymab.policies.ucb.SlidingWindowUCBPolicy.c" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.SlidingWindowUCBPolicy.window_size">
<span class="sig-name descname"><span class="pre">window_size</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></em><a class="headerlink" href="#pymab.policies.ucb.SlidingWindowUCBPolicy.window_size" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.SlidingWindowUCBPolicy.rewards_history">
<span class="sig-name descname"><span class="pre">rewards_history</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#pymab.policies.ucb.SlidingWindowUCBPolicy.rewards_history" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.ucb.SlidingWindowUCBPolicy.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_bandits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimistic_initialization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">variance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reward_distribution</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gaussian'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">window_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/ucb.html#SlidingWindowUCBPolicy.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.ucb.SlidingWindowUCBPolicy.__init__" title="Link to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>window_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – The number of most recent observations to consider for each arm.</p></li>
<li><p><strong>n_bandits</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>)</p></li>
<li><p><strong>optimistic_initialization</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>)</p></li>
<li><p><strong>variance</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>)</p></li>
<li><p><strong>reward_distribution</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>)</p></li>
<li><p><strong>c</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.ucb.SlidingWindowUCBPolicy._calculate_confidence_interval">
<span class="sig-name descname"><span class="pre">_calculate_confidence_interval</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_index</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/ucb.html#SlidingWindowUCBPolicy._calculate_confidence_interval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.ucb.SlidingWindowUCBPolicy._calculate_confidence_interval" title="Link to this definition">¶</a></dt>
<dd><p>Calculate the confidence interval for the Sliding Window UCB algorithm.</p>
<p>This method adapts the UCB confidence interval calculation to use a sliding window,
which allows the algorithm to adapt to non-stationary environments by focusing on
recent observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – The index of the action to calculate the confidence interval for.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The calculated confidence interval.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
<dt class="field-even">Theory<span class="colon">:</span></dt>
<dd class="field-even"><p>The confidence interval is calculated similarly to UCB1, but uses the minimum of
the current step (or window size) and the number of times the action has been selected
within the window.</p>
</dd>
<dt class="field-odd">Optimization<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>Uses min() to handle both the window size and the number of selections efficiently.</p></li>
<li><p>Adds 1 to the log term to avoid log(0) in the first step.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pymab.policies.ucb.SlidingWindowUCBPolicy.Q_values">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">Q_values</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#pymab.policies.ucb.SlidingWindowUCBPolicy.Q_values" title="Link to this definition">¶</a></dt>
<dd><p>Get the true Q-values for all actions.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>List of true Q-values.</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If Q-values haven’t been set.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.ucb.SlidingWindowUCBPolicy._get_actual_reward">
<span class="sig-name descname"><span class="pre">_get_actual_reward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_index</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.ucb.SlidingWindowUCBPolicy._get_actual_reward" title="Link to this definition">¶</a></dt>
<dd><p>Get the actual reward for a given action.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of the chosen action.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The reward value sampled from the distribution.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.ucb.SlidingWindowUCBPolicy._get_ucb_value">
<span class="sig-name descname"><span class="pre">_get_ucb_value</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_index</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.ucb.SlidingWindowUCBPolicy._get_ucb_value" title="Link to this definition">¶</a></dt>
<dd><p>Calculate the Upper Confidence Bound (UCB) value for a given action.</p>
<p>This method implements the core UCB algorithm by combining the estimated reward
with the confidence interval. It handles the case of unselected actions by
returning infinity, ensuring exploration of all actions initially.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – The index of the action to calculate the UCB value for.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The calculated UCB value, or infinity for unselected actions.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
<dt class="field-even">Theory<span class="colon">:</span></dt>
<dd class="field-even"><p>UCB = Q(a) + U(a), where Q(a) is the estimated reward and U(a) is the confidence interval.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.ucb.SlidingWindowUCBPolicy._update">
<span class="sig-name descname"><span class="pre">_update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">chosen_action_index</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.ucb.SlidingWindowUCBPolicy._update" title="Link to this definition">¶</a></dt>
<dd><p>Update the policy based on the chosen action and received reward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>chosen_action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of the chosen action.</p></li>
<li><p><strong>*args</strong> – Variable length argument list.</p></li>
<li><p><strong>**kwargs</strong> – Arbitrary keyword arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The reward received for the chosen action.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.ucb.SlidingWindowUCBPolicy._update_sliding_window">
<span class="sig-name descname"><span class="pre">_update_sliding_window</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">chosen_action_index</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.ucb.SlidingWindowUCBPolicy._update_sliding_window" title="Link to this definition">¶</a></dt>
<dd><p>Update the sliding window of rewards for a given action.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>chosen_action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of the chosen action.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>None</em></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method maintains a fixed-size window of recent rewards
and updates the estimated reward based on this window.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.ucb.SlidingWindowUCBPolicy.get_reward_distribution">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_reward_distribution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.ucb.SlidingWindowUCBPolicy.get_reward_distribution" title="Link to this definition">¶</a></dt>
<dd><p>Get the reward distribution class based on the given name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Name of the reward distribution.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The corresponding reward distribution class.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If an unknown distribution name is provided.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Type</em>[<a class="reference internal" href="reward_distribution.html#pymab.reward_distribution.RewardDistribution" title="pymab.reward_distribution.RewardDistribution"><em>RewardDistribution</em></a>]</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Supported distributions are:
- ‘gaussian’: Normal distribution
- ‘bernoulli’: Binary distribution
- ‘uniform’: Uniform distribution</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.ucb.SlidingWindowUCBPolicy.plot_distribution">
<span class="sig-name descname"><span class="pre">plot_distribution</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.ucb.SlidingWindowUCBPolicy.plot_distribution" title="Link to this definition">¶</a></dt>
<dd><p>Plot the distributions of the expected reward for the current step.</p>
<p>This method visualizes the reward distributions for all actions, showing
both the estimated rewards and true rewards (if known).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method handles both Bernoulli and Gaussian reward distributions.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>None</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.ucb.SlidingWindowUCBPolicy.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.ucb.SlidingWindowUCBPolicy.reset" title="Link to this definition">¶</a></dt>
<dd><p>Reset the policy to its initial state.</p>
<p>This method resets:
- Current step counter
- Total reward
- Action selection counts
- Estimated rewards
- Reward history</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.ucb.SlidingWindowUCBPolicy.select_action">
<span class="sig-name descname"><span class="pre">select_action</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.ucb.SlidingWindowUCBPolicy.select_action" title="Link to this definition">¶</a></dt>
<dd><p>Select the next action based on the UCB algorithm.</p>
<p>This method implements the action selection strategy of UCB:
1. Initially, it selects each action once to gather initial estimates.
2. After that, it chooses the action with the highest UCB value.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A tuple containing the index of the chosen action and the reward obtained from taking that action.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tuple</em>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>]</p>
</dd>
</dl>
<p>Examples:
Here’s how to use the <cite>select_action</cite> method:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">policy</span> <span class="o">=</span> <span class="n">UCBPolicy</span><span class="p">(</span><span class="n">n_bandits</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">action</span><span class="p">,</span> <span class="n">reward</span> <span class="o">=</span> <span class="n">policy</span><span class="o">.</span><span class="n">select_action</span><span class="p">()</span>
    <span class="c1"># Use the action and reward as needed</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pymab.policies.ucb.DiscountedUCBPolicy">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">DiscountedUCBPolicy</span></span><a class="reference internal" href="_modules/pymab/policies/ucb.html#DiscountedUCBPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.ucb.DiscountedUCBPolicy" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">DiscountedMixin</span></code>, <a class="reference internal" href="#pymab.policies.ucb.UCBPolicy" title="pymab.policies.ucb.UCBPolicy"><code class="xref py py-class docutils literal notranslate"><span class="pre">UCBPolicy</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.DiscountedUCBPolicy.n_bandits">
<span class="sig-name descname"><span class="pre">n_bandits</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></em><a class="headerlink" href="#pymab.policies.ucb.DiscountedUCBPolicy.n_bandits" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.DiscountedUCBPolicy.optimistic_initialization">
<span class="sig-name descname"><span class="pre">optimistic_initialization</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></em><a class="headerlink" href="#pymab.policies.ucb.DiscountedUCBPolicy.optimistic_initialization" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.DiscountedUCBPolicy.current_step">
<span class="sig-name descname"><span class="pre">current_step</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></em><a class="headerlink" href="#pymab.policies.ucb.DiscountedUCBPolicy.current_step" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.DiscountedUCBPolicy.total_reward">
<span class="sig-name descname"><span class="pre">total_reward</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></em><a class="headerlink" href="#pymab.policies.ucb.DiscountedUCBPolicy.total_reward" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.DiscountedUCBPolicy.times_selected">
<span class="sig-name descname"><span class="pre">times_selected</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">np.array</span></em><a class="headerlink" href="#pymab.policies.ucb.DiscountedUCBPolicy.times_selected" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.DiscountedUCBPolicy.actions_estimated_reward">
<span class="sig-name descname"><span class="pre">actions_estimated_reward</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">np.array</span></em><a class="headerlink" href="#pymab.policies.ucb.DiscountedUCBPolicy.actions_estimated_reward" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.DiscountedUCBPolicy.variance">
<span class="sig-name descname"><span class="pre">variance</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></em><a class="headerlink" href="#pymab.policies.ucb.DiscountedUCBPolicy.variance" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.DiscountedUCBPolicy.reward_distribution">
<span class="sig-name descname"><span class="pre">reward_distribution</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="reward_distribution.html#pymab.reward_distribution.RewardDistribution" title="pymab.reward_distribution.RewardDistribution"><span class="pre">RewardDistribution</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#pymab.policies.ucb.DiscountedUCBPolicy.reward_distribution" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.DiscountedUCBPolicy.c">
<span class="sig-name descname"><span class="pre">c</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></em><a class="headerlink" href="#pymab.policies.ucb.DiscountedUCBPolicy.c" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.DiscountedUCBPolicy.discount_factor">
<span class="sig-name descname"><span class="pre">discount_factor</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></em><a class="headerlink" href="#pymab.policies.ucb.DiscountedUCBPolicy.discount_factor" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.ucb.DiscountedUCBPolicy.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_bandits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimistic_initialization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">variance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reward_distribution</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gaussian'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discount_factor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.9</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/ucb.html#DiscountedUCBPolicy.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.ucb.DiscountedUCBPolicy.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initialize a Discounted UCB policy.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_bandits</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Number of bandits (arms) in the problem.</p></li>
<li><p><strong>optimistic_initialization</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Initial value for estimated rewards.</p></li>
<li><p><strong>variance</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Variance of the reward distribution.</p></li>
<li><p><strong>reward_distribution</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Type of reward distribution (“gaussian” or “bernoulli”).</p></li>
<li><p><strong>c</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Exploration parameter controlling confidence bound width.</p></li>
<li><p><strong>discount_factor</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Factor for discounting past rewards (between 0 and 1).</p></li>
</ul>
</dd>
</dl>
<p>The discount factor determines how much weight is given to past observations,
with values closer to 1 giving more weight to historical data.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.DiscountedUCBPolicy.effective_n">
<span class="sig-name descname"><span class="pre">effective_n</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></em><a class="headerlink" href="#pymab.policies.ucb.DiscountedUCBPolicy.effective_n" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.ucb.DiscountedUCBPolicy._calculate_confidence_interval">
<span class="sig-name descname"><span class="pre">_calculate_confidence_interval</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_index</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymab/policies/ucb.html#DiscountedUCBPolicy._calculate_confidence_interval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymab.policies.ucb.DiscountedUCBPolicy._calculate_confidence_interval" title="Link to this definition">¶</a></dt>
<dd><p>Calculate the confidence interval for the Discounted UCB algorithm.</p>
<p>This method implements the confidence interval calculation for Discounted UCB,
which uses a discount factor to give more weight to recent observations,
allowing adaptation to slowly varying non-stationary environments.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – The index of the action to calculate the confidence interval for.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The calculated confidence interval.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
<dt class="field-even">Theory<span class="colon">:</span></dt>
<dd class="field-even"><p>The confidence interval is calculated using the effective sample size (effective_n)
instead of the current time step. The effective_n is determined by the discount factor
and represents the equivalent number of observations if all had full weight.</p>
</dd>
<dt class="field-odd">Optimization<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>Precomputes effective_n in the constructor to avoid repeated calculations.</p></li>
<li><p>Uses min() to handle both the effective_n and the number of selections efficiently.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pymab.policies.ucb.DiscountedUCBPolicy.Q_values">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">Q_values</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#pymab.policies.ucb.DiscountedUCBPolicy.Q_values" title="Link to this definition">¶</a></dt>
<dd><p>Get the true Q-values for all actions.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>List of true Q-values.</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If Q-values haven’t been set.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.ucb.DiscountedUCBPolicy._get_actual_reward">
<span class="sig-name descname"><span class="pre">_get_actual_reward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_index</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.ucb.DiscountedUCBPolicy._get_actual_reward" title="Link to this definition">¶</a></dt>
<dd><p>Get the actual reward for a given action.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of the chosen action.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The reward value sampled from the distribution.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.ucb.DiscountedUCBPolicy._get_ucb_value">
<span class="sig-name descname"><span class="pre">_get_ucb_value</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_index</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.ucb.DiscountedUCBPolicy._get_ucb_value" title="Link to this definition">¶</a></dt>
<dd><p>Calculate the Upper Confidence Bound (UCB) value for a given action.</p>
<p>This method implements the core UCB algorithm by combining the estimated reward
with the confidence interval. It handles the case of unselected actions by
returning infinity, ensuring exploration of all actions initially.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – The index of the action to calculate the UCB value for.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The calculated UCB value, or infinity for unselected actions.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
<dt class="field-even">Theory<span class="colon">:</span></dt>
<dd class="field-even"><p>UCB = Q(a) + U(a), where Q(a) is the estimated reward and U(a) is the confidence interval.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.ucb.DiscountedUCBPolicy._update">
<span class="sig-name descname"><span class="pre">_update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">chosen_action_index</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.ucb.DiscountedUCBPolicy._update" title="Link to this definition">¶</a></dt>
<dd><p>Update the policy based on the chosen action and received reward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>chosen_action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of the chosen action.</p></li>
<li><p><strong>*args</strong> – Variable length argument list.</p></li>
<li><p><strong>**kwargs</strong> – Arbitrary keyword arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The reward received for the chosen action.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.ucb.DiscountedUCBPolicy._update_sliding_window">
<span class="sig-name descname"><span class="pre">_update_sliding_window</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">chosen_action_index</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.ucb.DiscountedUCBPolicy._update_sliding_window" title="Link to this definition">¶</a></dt>
<dd><p>Update the sliding window of rewards for a given action.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>chosen_action_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of the chosen action.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>None</em></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method maintains a fixed-size window of recent rewards
and updates the estimated reward based on this window.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.ucb.DiscountedUCBPolicy.get_reward_distribution">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_reward_distribution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.ucb.DiscountedUCBPolicy.get_reward_distribution" title="Link to this definition">¶</a></dt>
<dd><p>Get the reward distribution class based on the given name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Name of the reward distribution.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The corresponding reward distribution class.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If an unknown distribution name is provided.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Type</em>[<a class="reference internal" href="reward_distribution.html#pymab.reward_distribution.RewardDistribution" title="pymab.reward_distribution.RewardDistribution"><em>RewardDistribution</em></a>]</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Supported distributions are:
- ‘gaussian’: Normal distribution
- ‘bernoulli’: Binary distribution
- ‘uniform’: Uniform distribution</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.ucb.DiscountedUCBPolicy.plot_distribution">
<span class="sig-name descname"><span class="pre">plot_distribution</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.ucb.DiscountedUCBPolicy.plot_distribution" title="Link to this definition">¶</a></dt>
<dd><p>Plot the distributions of the expected reward for the current step.</p>
<p>This method visualizes the reward distributions for all actions, showing
both the estimated rewards and true rewards (if known).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method handles both Bernoulli and Gaussian reward distributions.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>None</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.ucb.DiscountedUCBPolicy.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.ucb.DiscountedUCBPolicy.reset" title="Link to this definition">¶</a></dt>
<dd><p>Reset the policy to its initial state.</p>
<p>This method resets:
- Current step counter
- Total reward
- Action selection counts
- Estimated rewards
- Reward history</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymab.policies.ucb.DiscountedUCBPolicy.select_action">
<span class="sig-name descname"><span class="pre">select_action</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymab.policies.ucb.DiscountedUCBPolicy.select_action" title="Link to this definition">¶</a></dt>
<dd><p>Select the next action based on the UCB algorithm.</p>
<p>This method implements the action selection strategy of UCB:
1. Initially, it selects each action once to gather initial estimates.
2. After that, it chooses the action with the highest UCB value.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A tuple containing the index of the chosen action and the reward obtained from taking that action.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tuple</em>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>]</p>
</dd>
</dl>
<p>Examples:
Here’s how to use the <cite>select_action</cite> method:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">policy</span> <span class="o">=</span> <span class="n">UCBPolicy</span><span class="p">(</span><span class="n">n_bandits</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">action</span><span class="p">,</span> <span class="n">reward</span> <span class="o">=</span> <span class="n">policy</span><span class="o">.</span><span class="n">select_action</span><span class="p">()</span>
    <span class="c1"># Use the action and reward as needed</span>
</pre></div>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pymab.policies.ucb.DiscountedUCBPolicy.rewards_history">
<span class="sig-name descname"><span class="pre">rewards_history</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#pymab.policies.ucb.DiscountedUCBPolicy.rewards_history" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<section id="example-usage">
<h3>Example Usage<a class="headerlink" href="#example-usage" title="Link to this heading">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pymab.policies.greedy</span> <span class="kn">import</span> <span class="n">GreedyPolicy</span>
<span class="kn">from</span> <span class="nn">pymab.policies.epsilon_greedy</span> <span class="kn">import</span> <span class="n">EpsilonGreedyPolicy</span>
<span class="kn">from</span> <span class="nn">pymab.policies.bayesian_ucb</span> <span class="kn">import</span> <span class="n">BayesianUCBPolicy</span>

<span class="kn">from</span> <span class="nn">pymab.policies.thompson_sampling</span> <span class="kn">import</span> <span class="n">ThompsonSamplingPolicy</span>
<span class="kn">from</span> <span class="nn">pymab.game</span> <span class="kn">import</span> <span class="n">Game</span>

<span class="n">n_bandits</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">greedy_policy</span> <span class="o">=</span> <span class="n">GreedyPolicy</span><span class="p">(</span><span class="n">n_bandits</span><span class="o">=</span><span class="n">n_bandits</span><span class="p">,</span>
                           <span class="n">optimistic_initialization</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">greedy_policy_optimistic_initialization_1</span> <span class="o">=</span> <span class="n">GreedyPolicy</span><span class="p">(</span><span class="n">n_bandits</span><span class="o">=</span><span class="n">n_bandits</span><span class="p">,</span>
                                                      <span class="n">optimistic_initialization</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">greedy_policy_optimistic_initialization_5</span> <span class="o">=</span> <span class="n">GreedyPolicy</span><span class="p">(</span><span class="n">n_bandits</span><span class="o">=</span><span class="n">n_bandits</span><span class="p">,</span>
                                                      <span class="n">optimistic_initialization</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">epsilon_greedy_policy_0_01</span> <span class="o">=</span> <span class="n">EpsilonGreedyPolicy</span><span class="p">(</span><span class="n">n_bandits</span><span class="o">=</span><span class="n">n_bandits</span><span class="p">,</span>
                                       <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="n">epsilon_greedy_policy_0_1</span> <span class="o">=</span> <span class="n">EpsilonGreedyPolicy</span><span class="p">(</span><span class="n">n_bandits</span><span class="o">=</span><span class="n">n_bandits</span><span class="p">,</span>
                                       <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="n">epsilon_greedy_policy_0_5</span> <span class="o">=</span> <span class="n">EpsilonGreedyPolicy</span><span class="p">(</span><span class="n">n_bandits</span><span class="o">=</span><span class="n">n_bandits</span><span class="p">,</span>
                                       <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="n">ucb_policy_0</span> <span class="o">=</span> <span class="n">BayesianUCBPolicy</span><span class="p">(</span><span class="n">n_bandits</span><span class="o">=</span><span class="n">n_bandits</span><span class="p">,</span>
                     <span class="n">c</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">ucb_policy_1</span> <span class="o">=</span> <span class="n">BayesianUCBPolicy</span><span class="p">(</span><span class="n">n_bandits</span><span class="o">=</span><span class="n">n_bandits</span><span class="p">,</span>
                     <span class="n">c</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">ucb_policy_2</span> <span class="o">=</span> <span class="n">BayesianUCBPolicy</span><span class="p">(</span><span class="n">n_bandits</span><span class="o">=</span><span class="n">n_bandits</span><span class="p">,</span>
                     <span class="n">c</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">thomson_sampling</span> <span class="o">=</span> <span class="n">ThompsonSamplingPolicy</span><span class="p">(</span><span class="n">n_bandits</span><span class="o">=</span><span class="n">n_bandits</span><span class="p">)</span>

<span class="n">n_bandits</span> <span class="o">=</span> <span class="mi">10</span>

<span class="c1"># Setup the game</span>
<span class="n">game</span> <span class="o">=</span> <span class="n">Game</span><span class="p">(</span><span class="n">n_episodes</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
            <span class="n">n_steps</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
            <span class="n">policies</span><span class="o">=</span><span class="p">[</span><span class="n">greedy_policy</span><span class="p">,</span>
                  <span class="n">greedy_policy_optimistic_initialization_1</span><span class="p">,</span>
                  <span class="n">greedy_policy_optimistic_initialization_5</span><span class="p">,</span>
                  <span class="n">epsilon_greedy_policy_0_01</span><span class="p">,</span>
                  <span class="n">epsilon_greedy_policy_0_1</span><span class="p">,</span>
                  <span class="n">epsilon_greedy_policy_0_5</span><span class="p">,</span>
                  <span class="n">ucb_policy_0</span><span class="p">,</span>
                  <span class="n">ucb_policy_1</span><span class="p">,</span>
                  <span class="n">ucb_policy_2</span><span class="p">,</span>
                  <span class="n">thomson_sampling</span>
               <span class="p">],</span>
            <span class="n">n_bandits</span><span class="o">=</span><span class="n">n_bandits</span><span class="p">,</span>
            <span class="p">)</span>

<span class="n">game</span><span class="o">.</span><span class="n">game_loop</span><span class="p">()</span>

<span class="n">game</span><span class="o">.</span><span class="n">plot_average_reward_by_step</span><span class="p">()</span>
</pre></div>
</div>
</section>
</section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
    
        <div id="show_right_sidebar">
            <p><a class="toggle_right_sidebar" href="#"><span class="icon">&lt;</span><span>Page contents</span></a></p>
        </div>

        <div id="right_sidebar">
            <p><a class="toggle_right_sidebar" href="#"><span class="icon">&gt;</span><span>Page contents:</span></a></p>
            <div class="page_toc">
                <ul>
<li><a class="reference internal" href="#">Policies documentation</a><ul>
<li><a class="reference internal" href="#policy-policy-py">Policy (policy.py)</a><ul>
<li><a class="reference internal" href="#pymab.policies.policy.no_context_func"><code class="docutils literal notranslate"><span class="pre">no_context_func()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.policy.Policy"><code class="docutils literal notranslate"><span class="pre">Policy</span></code></a><ul>
<li><a class="reference internal" href="#pymab.policies.policy.Policy.n_bandits"><code class="docutils literal notranslate"><span class="pre">Policy.n_bandits</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.policy.Policy.optimistic_initialization"><code class="docutils literal notranslate"><span class="pre">Policy.optimistic_initialization</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.policy.Policy._Q_values"><code class="docutils literal notranslate"><span class="pre">Policy._Q_values</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.policy.Policy.current_step"><code class="docutils literal notranslate"><span class="pre">Policy.current_step</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.policy.Policy.total_reward"><code class="docutils literal notranslate"><span class="pre">Policy.total_reward</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.policy.Policy.times_selected"><code class="docutils literal notranslate"><span class="pre">Policy.times_selected</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.policy.Policy.actions_estimated_reward"><code class="docutils literal notranslate"><span class="pre">Policy.actions_estimated_reward</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.policy.Policy.variance"><code class="docutils literal notranslate"><span class="pre">Policy.variance</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.policy.Policy.reward_distribution"><code class="docutils literal notranslate"><span class="pre">Policy.reward_distribution</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.policy.Policy.context_func"><code class="docutils literal notranslate"><span class="pre">Policy.context_func</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.policy.Policy.rewards_history"><code class="docutils literal notranslate"><span class="pre">Policy.rewards_history</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.policy.Policy.__init__"><code class="docutils literal notranslate"><span class="pre">Policy.__init__()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.policy.Policy.get_reward_distribution"><code class="docutils literal notranslate"><span class="pre">Policy.get_reward_distribution()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.policy.Policy._get_actual_reward"><code class="docutils literal notranslate"><span class="pre">Policy._get_actual_reward()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.policy.Policy._update"><code class="docutils literal notranslate"><span class="pre">Policy._update()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.policy.Policy._update_estimate"><code class="docutils literal notranslate"><span class="pre">Policy._update_estimate()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.policy.Policy._update_sliding_window"><code class="docutils literal notranslate"><span class="pre">Policy._update_sliding_window()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.policy.Policy.Q_values"><code class="docutils literal notranslate"><span class="pre">Policy.Q_values</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.policy.Policy.select_action"><code class="docutils literal notranslate"><span class="pre">Policy.select_action()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.policy.Policy.reset"><code class="docutils literal notranslate"><span class="pre">Policy.reset()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.policy.Policy.plot_distribution"><code class="docutils literal notranslate"><span class="pre">Policy.plot_distribution()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#bayesian-ucb-bayesian-ucb-py">Bayesian UCB (bayesian_ucb.py)</a><ul>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy"><code class="docutils literal notranslate"><span class="pre">BernoulliBayesianUCBPolicy</span></code></a><ul>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.successes"><code class="docutils literal notranslate"><span class="pre">BernoulliBayesianUCBPolicy.successes</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.failures"><code class="docutils literal notranslate"><span class="pre">BernoulliBayesianUCBPolicy.failures</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.n_bandits"><code class="docutils literal notranslate"><span class="pre">BernoulliBayesianUCBPolicy.n_bandits</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.optimistic_initialization"><code class="docutils literal notranslate"><span class="pre">BernoulliBayesianUCBPolicy.optimistic_initialization</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.current_step"><code class="docutils literal notranslate"><span class="pre">BernoulliBayesianUCBPolicy.current_step</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.total_reward"><code class="docutils literal notranslate"><span class="pre">BernoulliBayesianUCBPolicy.total_reward</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.times_selected"><code class="docutils literal notranslate"><span class="pre">BernoulliBayesianUCBPolicy.times_selected</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.actions_estimated_reward"><code class="docutils literal notranslate"><span class="pre">BernoulliBayesianUCBPolicy.actions_estimated_reward</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.variance"><code class="docutils literal notranslate"><span class="pre">BernoulliBayesianUCBPolicy.variance</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.reward_distribution"><code class="docutils literal notranslate"><span class="pre">BernoulliBayesianUCBPolicy.reward_distribution</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.c"><code class="docutils literal notranslate"><span class="pre">BernoulliBayesianUCBPolicy.c</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.__init__"><code class="docutils literal notranslate"><span class="pre">BernoulliBayesianUCBPolicy.__init__()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy._get_ucb_value"><code class="docutils literal notranslate"><span class="pre">BernoulliBayesianUCBPolicy._get_ucb_value()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy._update"><code class="docutils literal notranslate"><span class="pre">BernoulliBayesianUCBPolicy._update()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.Q_values"><code class="docutils literal notranslate"><span class="pre">BernoulliBayesianUCBPolicy.Q_values</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy._calculate_confidence_interval"><code class="docutils literal notranslate"><span class="pre">BernoulliBayesianUCBPolicy._calculate_confidence_interval()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy._get_actual_reward"><code class="docutils literal notranslate"><span class="pre">BernoulliBayesianUCBPolicy._get_actual_reward()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy._update_sliding_window"><code class="docutils literal notranslate"><span class="pre">BernoulliBayesianUCBPolicy._update_sliding_window()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.get_reward_distribution"><code class="docutils literal notranslate"><span class="pre">BernoulliBayesianUCBPolicy.get_reward_distribution()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.plot_distribution"><code class="docutils literal notranslate"><span class="pre">BernoulliBayesianUCBPolicy.plot_distribution()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.reset"><code class="docutils literal notranslate"><span class="pre">BernoulliBayesianUCBPolicy.reset()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.select_action"><code class="docutils literal notranslate"><span class="pre">BernoulliBayesianUCBPolicy.select_action()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.BernoulliBayesianUCBPolicy.rewards_history"><code class="docutils literal notranslate"><span class="pre">BernoulliBayesianUCBPolicy.rewards_history</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy"><code class="docutils literal notranslate"><span class="pre">GaussianBayesianUCBPolicy</span></code></a><ul>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.sum_rewards"><code class="docutils literal notranslate"><span class="pre">GaussianBayesianUCBPolicy.sum_rewards</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.sum_squared_rewards"><code class="docutils literal notranslate"><span class="pre">GaussianBayesianUCBPolicy.sum_squared_rewards</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.n_bandits"><code class="docutils literal notranslate"><span class="pre">GaussianBayesianUCBPolicy.n_bandits</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.optimistic_initialization"><code class="docutils literal notranslate"><span class="pre">GaussianBayesianUCBPolicy.optimistic_initialization</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.current_step"><code class="docutils literal notranslate"><span class="pre">GaussianBayesianUCBPolicy.current_step</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.total_reward"><code class="docutils literal notranslate"><span class="pre">GaussianBayesianUCBPolicy.total_reward</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.times_selected"><code class="docutils literal notranslate"><span class="pre">GaussianBayesianUCBPolicy.times_selected</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.actions_estimated_reward"><code class="docutils literal notranslate"><span class="pre">GaussianBayesianUCBPolicy.actions_estimated_reward</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.variance"><code class="docutils literal notranslate"><span class="pre">GaussianBayesianUCBPolicy.variance</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.reward_distribution"><code class="docutils literal notranslate"><span class="pre">GaussianBayesianUCBPolicy.reward_distribution</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.c"><code class="docutils literal notranslate"><span class="pre">GaussianBayesianUCBPolicy.c</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.__init__"><code class="docutils literal notranslate"><span class="pre">GaussianBayesianUCBPolicy.__init__()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy._get_ucb_value"><code class="docutils literal notranslate"><span class="pre">GaussianBayesianUCBPolicy._get_ucb_value()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy._update"><code class="docutils literal notranslate"><span class="pre">GaussianBayesianUCBPolicy._update()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.Q_values"><code class="docutils literal notranslate"><span class="pre">GaussianBayesianUCBPolicy.Q_values</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy._calculate_confidence_interval"><code class="docutils literal notranslate"><span class="pre">GaussianBayesianUCBPolicy._calculate_confidence_interval()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy._get_actual_reward"><code class="docutils literal notranslate"><span class="pre">GaussianBayesianUCBPolicy._get_actual_reward()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy._update_sliding_window"><code class="docutils literal notranslate"><span class="pre">GaussianBayesianUCBPolicy._update_sliding_window()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.get_reward_distribution"><code class="docutils literal notranslate"><span class="pre">GaussianBayesianUCBPolicy.get_reward_distribution()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.plot_distribution"><code class="docutils literal notranslate"><span class="pre">GaussianBayesianUCBPolicy.plot_distribution()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.reset"><code class="docutils literal notranslate"><span class="pre">GaussianBayesianUCBPolicy.reset()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.select_action"><code class="docutils literal notranslate"><span class="pre">GaussianBayesianUCBPolicy.select_action()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.GaussianBayesianUCBPolicy.rewards_history"><code class="docutils literal notranslate"><span class="pre">GaussianBayesianUCBPolicy.rewards_history</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.BayesianUCBPolicy"><code class="docutils literal notranslate"><span class="pre">BayesianUCBPolicy</span></code></a><ul>
<li><a class="reference internal" href="#pymab.policies.bayesian_ucb.BayesianUCBPolicy.__new__"><code class="docutils literal notranslate"><span class="pre">BayesianUCBPolicy.__new__()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#contextual-bandits-contextual-bandits-py">Contextual Bandits (contextual_bandits.py)</a><ul>
<li><a class="reference internal" href="#pymab.policies.contextual_bandits.ContextualBanditPolicy"><code class="docutils literal notranslate"><span class="pre">ContextualBanditPolicy</span></code></a><ul>
<li><a class="reference internal" href="#pymab.policies.contextual_bandits.ContextualBanditPolicy.context_dim"><code class="docutils literal notranslate"><span class="pre">ContextualBanditPolicy.context_dim</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.contextual_bandits.ContextualBanditPolicy.theta"><code class="docutils literal notranslate"><span class="pre">ContextualBanditPolicy.theta</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.contextual_bandits.ContextualBanditPolicy.learning_rate"><code class="docutils literal notranslate"><span class="pre">ContextualBanditPolicy.learning_rate</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.contextual_bandits.ContextualBanditPolicy.__init__"><code class="docutils literal notranslate"><span class="pre">ContextualBanditPolicy.__init__()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.contextual_bandits.ContextualBanditPolicy._update"><code class="docutils literal notranslate"><span class="pre">ContextualBanditPolicy._update()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.contextual_bandits.ContextualBanditPolicy.reset"><code class="docutils literal notranslate"><span class="pre">ContextualBanditPolicy.reset()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.contextual_bandits.ContextualBanditPolicy.select_action"><code class="docutils literal notranslate"><span class="pre">ContextualBanditPolicy.select_action()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.contextual_bandits.ContextualBanditPolicy.Q_values"><code class="docutils literal notranslate"><span class="pre">ContextualBanditPolicy.Q_values</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.contextual_bandits.ContextualBanditPolicy._get_actual_reward"><code class="docutils literal notranslate"><span class="pre">ContextualBanditPolicy._get_actual_reward()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.contextual_bandits.ContextualBanditPolicy._update_sliding_window"><code class="docutils literal notranslate"><span class="pre">ContextualBanditPolicy._update_sliding_window()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.contextual_bandits.ContextualBanditPolicy.get_reward_distribution"><code class="docutils literal notranslate"><span class="pre">ContextualBanditPolicy.get_reward_distribution()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.contextual_bandits.ContextualBanditPolicy.plot_distribution"><code class="docutils literal notranslate"><span class="pre">ContextualBanditPolicy.plot_distribution()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#epsilon-greedy-epsilon-greedy-py">Epsilon Greedy (epsilon_greedy.py)</a><ul>
<li><a class="reference internal" href="#pymab.policies.epsilon_greedy.EpsilonGreedyPolicy"><code class="docutils literal notranslate"><span class="pre">EpsilonGreedyPolicy</span></code></a><ul>
<li><a class="reference internal" href="#pymab.policies.epsilon_greedy.EpsilonGreedyPolicy.epsilon"><code class="docutils literal notranslate"><span class="pre">EpsilonGreedyPolicy.epsilon</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.epsilon_greedy.EpsilonGreedyPolicy.__init__"><code class="docutils literal notranslate"><span class="pre">EpsilonGreedyPolicy.__init__()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.epsilon_greedy.EpsilonGreedyPolicy.select_action"><code class="docutils literal notranslate"><span class="pre">EpsilonGreedyPolicy.select_action()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.epsilon_greedy.EpsilonGreedyPolicy.Q_values"><code class="docutils literal notranslate"><span class="pre">EpsilonGreedyPolicy.Q_values</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.epsilon_greedy.EpsilonGreedyPolicy._get_actual_reward"><code class="docutils literal notranslate"><span class="pre">EpsilonGreedyPolicy._get_actual_reward()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.epsilon_greedy.EpsilonGreedyPolicy._update"><code class="docutils literal notranslate"><span class="pre">EpsilonGreedyPolicy._update()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.epsilon_greedy.EpsilonGreedyPolicy._update_sliding_window"><code class="docutils literal notranslate"><span class="pre">EpsilonGreedyPolicy._update_sliding_window()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.epsilon_greedy.EpsilonGreedyPolicy.get_reward_distribution"><code class="docutils literal notranslate"><span class="pre">EpsilonGreedyPolicy.get_reward_distribution()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.epsilon_greedy.EpsilonGreedyPolicy.plot_distribution"><code class="docutils literal notranslate"><span class="pre">EpsilonGreedyPolicy.plot_distribution()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.epsilon_greedy.EpsilonGreedyPolicy.reset"><code class="docutils literal notranslate"><span class="pre">EpsilonGreedyPolicy.reset()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#gradient-gradient-py">Gradient (gradient.py)</a></li>
<li><a class="reference internal" href="#greedy-greedy-py">Greedy (greedy.py)</a><ul>
<li><a class="reference internal" href="#pymab.policies.greedy.GreedyPolicy"><code class="docutils literal notranslate"><span class="pre">GreedyPolicy</span></code></a><ul>
<li><a class="reference internal" href="#pymab.policies.greedy.GreedyPolicy.__init__"><code class="docutils literal notranslate"><span class="pre">GreedyPolicy.__init__()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.greedy.GreedyPolicy.select_action"><code class="docutils literal notranslate"><span class="pre">GreedyPolicy.select_action()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.greedy.GreedyPolicy.Q_values"><code class="docutils literal notranslate"><span class="pre">GreedyPolicy.Q_values</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.greedy.GreedyPolicy._get_actual_reward"><code class="docutils literal notranslate"><span class="pre">GreedyPolicy._get_actual_reward()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.greedy.GreedyPolicy._update"><code class="docutils literal notranslate"><span class="pre">GreedyPolicy._update()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.greedy.GreedyPolicy._update_sliding_window"><code class="docutils literal notranslate"><span class="pre">GreedyPolicy._update_sliding_window()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.greedy.GreedyPolicy.get_reward_distribution"><code class="docutils literal notranslate"><span class="pre">GreedyPolicy.get_reward_distribution()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.greedy.GreedyPolicy.plot_distribution"><code class="docutils literal notranslate"><span class="pre">GreedyPolicy.plot_distribution()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.greedy.GreedyPolicy.reset"><code class="docutils literal notranslate"><span class="pre">GreedyPolicy.reset()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#softmax-selection-softmax-selection-py">Softmax Selection (softmax_selection.py)</a></li>
<li><a class="reference internal" href="#thompson-sampling-thompson-sampling-py">Thompson Sampling (thompson_sampling.py)</a><ul>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy"><code class="docutils literal notranslate"><span class="pre">BernoulliThompsonSamplingPolicy</span></code></a><ul>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.successes"><code class="docutils literal notranslate"><span class="pre">BernoulliThompsonSamplingPolicy.successes</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.failures"><code class="docutils literal notranslate"><span class="pre">BernoulliThompsonSamplingPolicy.failures</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.thomson_sampled"><code class="docutils literal notranslate"><span class="pre">BernoulliThompsonSamplingPolicy.thomson_sampled</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.n_bandits"><code class="docutils literal notranslate"><span class="pre">BernoulliThompsonSamplingPolicy.n_bandits</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.optimistic_initialization"><code class="docutils literal notranslate"><span class="pre">BernoulliThompsonSamplingPolicy.optimistic_initialization</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.current_step"><code class="docutils literal notranslate"><span class="pre">BernoulliThompsonSamplingPolicy.current_step</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.total_reward"><code class="docutils literal notranslate"><span class="pre">BernoulliThompsonSamplingPolicy.total_reward</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.times_selected"><code class="docutils literal notranslate"><span class="pre">BernoulliThompsonSamplingPolicy.times_selected</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.actions_estimated_reward"><code class="docutils literal notranslate"><span class="pre">BernoulliThompsonSamplingPolicy.actions_estimated_reward</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.variance"><code class="docutils literal notranslate"><span class="pre">BernoulliThompsonSamplingPolicy.variance</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.reward_distribution"><code class="docutils literal notranslate"><span class="pre">BernoulliThompsonSamplingPolicy.reward_distribution</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.rewards_history"><code class="docutils literal notranslate"><span class="pre">BernoulliThompsonSamplingPolicy.rewards_history</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.__init__"><code class="docutils literal notranslate"><span class="pre">BernoulliThompsonSamplingPolicy.__init__()</span></code></a></li>
<li><a class="reference internal" href="#id0"><code class="docutils literal notranslate"><span class="pre">BernoulliThompsonSamplingPolicy.successes</span></code></a></li>
<li><a class="reference internal" href="#id29"><code class="docutils literal notranslate"><span class="pre">BernoulliThompsonSamplingPolicy.failures</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy._update"><code class="docutils literal notranslate"><span class="pre">BernoulliThompsonSamplingPolicy._update()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.select_action"><code class="docutils literal notranslate"><span class="pre">BernoulliThompsonSamplingPolicy.select_action()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.plot_distribution"><code class="docutils literal notranslate"><span class="pre">BernoulliThompsonSamplingPolicy.plot_distribution()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.Q_values"><code class="docutils literal notranslate"><span class="pre">BernoulliThompsonSamplingPolicy.Q_values</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy._get_actual_reward"><code class="docutils literal notranslate"><span class="pre">BernoulliThompsonSamplingPolicy._get_actual_reward()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy._update_sliding_window"><code class="docutils literal notranslate"><span class="pre">BernoulliThompsonSamplingPolicy._update_sliding_window()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.get_reward_distribution"><code class="docutils literal notranslate"><span class="pre">BernoulliThompsonSamplingPolicy.get_reward_distribution()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.BernoulliThompsonSamplingPolicy.reset"><code class="docutils literal notranslate"><span class="pre">BernoulliThompsonSamplingPolicy.reset()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy"><code class="docutils literal notranslate"><span class="pre">GaussianThompsonSamplingPolicy</span></code></a><ul>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.means"><code class="docutils literal notranslate"><span class="pre">GaussianThompsonSamplingPolicy.means</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.precisions"><code class="docutils literal notranslate"><span class="pre">GaussianThompsonSamplingPolicy.precisions</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.n_bandits"><code class="docutils literal notranslate"><span class="pre">GaussianThompsonSamplingPolicy.n_bandits</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.optimistic_initialization"><code class="docutils literal notranslate"><span class="pre">GaussianThompsonSamplingPolicy.optimistic_initialization</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.current_step"><code class="docutils literal notranslate"><span class="pre">GaussianThompsonSamplingPolicy.current_step</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.total_reward"><code class="docutils literal notranslate"><span class="pre">GaussianThompsonSamplingPolicy.total_reward</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.times_selected"><code class="docutils literal notranslate"><span class="pre">GaussianThompsonSamplingPolicy.times_selected</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.actions_estimated_reward"><code class="docutils literal notranslate"><span class="pre">GaussianThompsonSamplingPolicy.actions_estimated_reward</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.variance"><code class="docutils literal notranslate"><span class="pre">GaussianThompsonSamplingPolicy.variance</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.reward_distribution"><code class="docutils literal notranslate"><span class="pre">GaussianThompsonSamplingPolicy.reward_distribution</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.__init__"><code class="docutils literal notranslate"><span class="pre">GaussianThompsonSamplingPolicy.__init__()</span></code></a></li>
<li><a class="reference internal" href="#id38"><code class="docutils literal notranslate"><span class="pre">GaussianThompsonSamplingPolicy.means</span></code></a></li>
<li><a class="reference internal" href="#id39"><code class="docutils literal notranslate"><span class="pre">GaussianThompsonSamplingPolicy.precisions</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy._update"><code class="docutils literal notranslate"><span class="pre">GaussianThompsonSamplingPolicy._update()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.select_action"><code class="docutils literal notranslate"><span class="pre">GaussianThompsonSamplingPolicy.select_action()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.Q_values"><code class="docutils literal notranslate"><span class="pre">GaussianThompsonSamplingPolicy.Q_values</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy._get_actual_reward"><code class="docutils literal notranslate"><span class="pre">GaussianThompsonSamplingPolicy._get_actual_reward()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy._update_sliding_window"><code class="docutils literal notranslate"><span class="pre">GaussianThompsonSamplingPolicy._update_sliding_window()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.get_reward_distribution"><code class="docutils literal notranslate"><span class="pre">GaussianThompsonSamplingPolicy.get_reward_distribution()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.reset"><code class="docutils literal notranslate"><span class="pre">GaussianThompsonSamplingPolicy.reset()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.GaussianThompsonSamplingPolicy.plot_distribution"><code class="docutils literal notranslate"><span class="pre">GaussianThompsonSamplingPolicy.plot_distribution()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.ThompsonSamplingPolicy"><code class="docutils literal notranslate"><span class="pre">ThompsonSamplingPolicy</span></code></a><ul>
<li><a class="reference internal" href="#pymab.policies.thompson_sampling.ThompsonSamplingPolicy.__new__"><code class="docutils literal notranslate"><span class="pre">ThompsonSamplingPolicy.__new__()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#ucb-ucb-py">UCB (ucb.py)</a><ul>
<li><a class="reference internal" href="#pymab.policies.ucb.UCBPolicy"><code class="docutils literal notranslate"><span class="pre">UCBPolicy</span></code></a><ul>
<li><a class="reference internal" href="#pymab.policies.ucb.UCBPolicy.n_bandits"><code class="docutils literal notranslate"><span class="pre">UCBPolicy.n_bandits</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.UCBPolicy.optimistic_initialization"><code class="docutils literal notranslate"><span class="pre">UCBPolicy.optimistic_initialization</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.UCBPolicy.current_step"><code class="docutils literal notranslate"><span class="pre">UCBPolicy.current_step</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.UCBPolicy.total_reward"><code class="docutils literal notranslate"><span class="pre">UCBPolicy.total_reward</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.UCBPolicy.times_selected"><code class="docutils literal notranslate"><span class="pre">UCBPolicy.times_selected</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.UCBPolicy.actions_estimated_reward"><code class="docutils literal notranslate"><span class="pre">UCBPolicy.actions_estimated_reward</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.UCBPolicy.variance"><code class="docutils literal notranslate"><span class="pre">UCBPolicy.variance</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.UCBPolicy.reward_distribution"><code class="docutils literal notranslate"><span class="pre">UCBPolicy.reward_distribution</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.UCBPolicy.rewards_history"><code class="docutils literal notranslate"><span class="pre">UCBPolicy.rewards_history</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.UCBPolicy.__init__"><code class="docutils literal notranslate"><span class="pre">UCBPolicy.__init__()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.UCBPolicy.c"><code class="docutils literal notranslate"><span class="pre">UCBPolicy.c</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.UCBPolicy._calculate_confidence_interval"><code class="docutils literal notranslate"><span class="pre">UCBPolicy._calculate_confidence_interval()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.UCBPolicy._get_ucb_value"><code class="docutils literal notranslate"><span class="pre">UCBPolicy._get_ucb_value()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.UCBPolicy.select_action"><code class="docutils literal notranslate"><span class="pre">UCBPolicy.select_action()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.UCBPolicy.Q_values"><code class="docutils literal notranslate"><span class="pre">UCBPolicy.Q_values</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.UCBPolicy._get_actual_reward"><code class="docutils literal notranslate"><span class="pre">UCBPolicy._get_actual_reward()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.UCBPolicy._update"><code class="docutils literal notranslate"><span class="pre">UCBPolicy._update()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.UCBPolicy._update_sliding_window"><code class="docutils literal notranslate"><span class="pre">UCBPolicy._update_sliding_window()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.UCBPolicy.get_reward_distribution"><code class="docutils literal notranslate"><span class="pre">UCBPolicy.get_reward_distribution()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.UCBPolicy.plot_distribution"><code class="docutils literal notranslate"><span class="pre">UCBPolicy.plot_distribution()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.UCBPolicy.reset"><code class="docutils literal notranslate"><span class="pre">UCBPolicy.reset()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#pymab.policies.ucb.StationaryUCBPolicy"><code class="docutils literal notranslate"><span class="pre">StationaryUCBPolicy</span></code></a><ul>
<li><a class="reference internal" href="#pymab.policies.ucb.StationaryUCBPolicy.n_bandits"><code class="docutils literal notranslate"><span class="pre">StationaryUCBPolicy.n_bandits</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.StationaryUCBPolicy.optimistic_initialization"><code class="docutils literal notranslate"><span class="pre">StationaryUCBPolicy.optimistic_initialization</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.StationaryUCBPolicy.current_step"><code class="docutils literal notranslate"><span class="pre">StationaryUCBPolicy.current_step</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.StationaryUCBPolicy.total_reward"><code class="docutils literal notranslate"><span class="pre">StationaryUCBPolicy.total_reward</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.StationaryUCBPolicy.times_selected"><code class="docutils literal notranslate"><span class="pre">StationaryUCBPolicy.times_selected</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.StationaryUCBPolicy.actions_estimated_reward"><code class="docutils literal notranslate"><span class="pre">StationaryUCBPolicy.actions_estimated_reward</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.StationaryUCBPolicy.variance"><code class="docutils literal notranslate"><span class="pre">StationaryUCBPolicy.variance</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.StationaryUCBPolicy.reward_distribution"><code class="docutils literal notranslate"><span class="pre">StationaryUCBPolicy.reward_distribution</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.StationaryUCBPolicy.c"><code class="docutils literal notranslate"><span class="pre">StationaryUCBPolicy.c</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.StationaryUCBPolicy._calculate_confidence_interval"><code class="docutils literal notranslate"><span class="pre">StationaryUCBPolicy._calculate_confidence_interval()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.StationaryUCBPolicy.Q_values"><code class="docutils literal notranslate"><span class="pre">StationaryUCBPolicy.Q_values</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.StationaryUCBPolicy.__init__"><code class="docutils literal notranslate"><span class="pre">StationaryUCBPolicy.__init__()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.StationaryUCBPolicy._get_actual_reward"><code class="docutils literal notranslate"><span class="pre">StationaryUCBPolicy._get_actual_reward()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.StationaryUCBPolicy._get_ucb_value"><code class="docutils literal notranslate"><span class="pre">StationaryUCBPolicy._get_ucb_value()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.StationaryUCBPolicy._update"><code class="docutils literal notranslate"><span class="pre">StationaryUCBPolicy._update()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.StationaryUCBPolicy._update_sliding_window"><code class="docutils literal notranslate"><span class="pre">StationaryUCBPolicy._update_sliding_window()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.StationaryUCBPolicy.get_reward_distribution"><code class="docutils literal notranslate"><span class="pre">StationaryUCBPolicy.get_reward_distribution()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.StationaryUCBPolicy.plot_distribution"><code class="docutils literal notranslate"><span class="pre">StationaryUCBPolicy.plot_distribution()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.StationaryUCBPolicy.reset"><code class="docutils literal notranslate"><span class="pre">StationaryUCBPolicy.reset()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.StationaryUCBPolicy.select_action"><code class="docutils literal notranslate"><span class="pre">StationaryUCBPolicy.select_action()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.StationaryUCBPolicy.rewards_history"><code class="docutils literal notranslate"><span class="pre">StationaryUCBPolicy.rewards_history</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#pymab.policies.ucb.SlidingWindowUCBPolicy"><code class="docutils literal notranslate"><span class="pre">SlidingWindowUCBPolicy</span></code></a><ul>
<li><a class="reference internal" href="#pymab.policies.ucb.SlidingWindowUCBPolicy.n_bandits"><code class="docutils literal notranslate"><span class="pre">SlidingWindowUCBPolicy.n_bandits</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.SlidingWindowUCBPolicy.optimistic_initialization"><code class="docutils literal notranslate"><span class="pre">SlidingWindowUCBPolicy.optimistic_initialization</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.SlidingWindowUCBPolicy.current_step"><code class="docutils literal notranslate"><span class="pre">SlidingWindowUCBPolicy.current_step</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.SlidingWindowUCBPolicy.total_reward"><code class="docutils literal notranslate"><span class="pre">SlidingWindowUCBPolicy.total_reward</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.SlidingWindowUCBPolicy.times_selected"><code class="docutils literal notranslate"><span class="pre">SlidingWindowUCBPolicy.times_selected</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.SlidingWindowUCBPolicy.actions_estimated_reward"><code class="docutils literal notranslate"><span class="pre">SlidingWindowUCBPolicy.actions_estimated_reward</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.SlidingWindowUCBPolicy.variance"><code class="docutils literal notranslate"><span class="pre">SlidingWindowUCBPolicy.variance</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.SlidingWindowUCBPolicy.reward_distribution"><code class="docutils literal notranslate"><span class="pre">SlidingWindowUCBPolicy.reward_distribution</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.SlidingWindowUCBPolicy.c"><code class="docutils literal notranslate"><span class="pre">SlidingWindowUCBPolicy.c</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.SlidingWindowUCBPolicy.window_size"><code class="docutils literal notranslate"><span class="pre">SlidingWindowUCBPolicy.window_size</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.SlidingWindowUCBPolicy.rewards_history"><code class="docutils literal notranslate"><span class="pre">SlidingWindowUCBPolicy.rewards_history</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.SlidingWindowUCBPolicy.__init__"><code class="docutils literal notranslate"><span class="pre">SlidingWindowUCBPolicy.__init__()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.SlidingWindowUCBPolicy._calculate_confidence_interval"><code class="docutils literal notranslate"><span class="pre">SlidingWindowUCBPolicy._calculate_confidence_interval()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.SlidingWindowUCBPolicy.Q_values"><code class="docutils literal notranslate"><span class="pre">SlidingWindowUCBPolicy.Q_values</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.SlidingWindowUCBPolicy._get_actual_reward"><code class="docutils literal notranslate"><span class="pre">SlidingWindowUCBPolicy._get_actual_reward()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.SlidingWindowUCBPolicy._get_ucb_value"><code class="docutils literal notranslate"><span class="pre">SlidingWindowUCBPolicy._get_ucb_value()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.SlidingWindowUCBPolicy._update"><code class="docutils literal notranslate"><span class="pre">SlidingWindowUCBPolicy._update()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.SlidingWindowUCBPolicy._update_sliding_window"><code class="docutils literal notranslate"><span class="pre">SlidingWindowUCBPolicy._update_sliding_window()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.SlidingWindowUCBPolicy.get_reward_distribution"><code class="docutils literal notranslate"><span class="pre">SlidingWindowUCBPolicy.get_reward_distribution()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.SlidingWindowUCBPolicy.plot_distribution"><code class="docutils literal notranslate"><span class="pre">SlidingWindowUCBPolicy.plot_distribution()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.SlidingWindowUCBPolicy.reset"><code class="docutils literal notranslate"><span class="pre">SlidingWindowUCBPolicy.reset()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.SlidingWindowUCBPolicy.select_action"><code class="docutils literal notranslate"><span class="pre">SlidingWindowUCBPolicy.select_action()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#pymab.policies.ucb.DiscountedUCBPolicy"><code class="docutils literal notranslate"><span class="pre">DiscountedUCBPolicy</span></code></a><ul>
<li><a class="reference internal" href="#pymab.policies.ucb.DiscountedUCBPolicy.n_bandits"><code class="docutils literal notranslate"><span class="pre">DiscountedUCBPolicy.n_bandits</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.DiscountedUCBPolicy.optimistic_initialization"><code class="docutils literal notranslate"><span class="pre">DiscountedUCBPolicy.optimistic_initialization</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.DiscountedUCBPolicy.current_step"><code class="docutils literal notranslate"><span class="pre">DiscountedUCBPolicy.current_step</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.DiscountedUCBPolicy.total_reward"><code class="docutils literal notranslate"><span class="pre">DiscountedUCBPolicy.total_reward</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.DiscountedUCBPolicy.times_selected"><code class="docutils literal notranslate"><span class="pre">DiscountedUCBPolicy.times_selected</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.DiscountedUCBPolicy.actions_estimated_reward"><code class="docutils literal notranslate"><span class="pre">DiscountedUCBPolicy.actions_estimated_reward</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.DiscountedUCBPolicy.variance"><code class="docutils literal notranslate"><span class="pre">DiscountedUCBPolicy.variance</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.DiscountedUCBPolicy.reward_distribution"><code class="docutils literal notranslate"><span class="pre">DiscountedUCBPolicy.reward_distribution</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.DiscountedUCBPolicy.c"><code class="docutils literal notranslate"><span class="pre">DiscountedUCBPolicy.c</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.DiscountedUCBPolicy.discount_factor"><code class="docutils literal notranslate"><span class="pre">DiscountedUCBPolicy.discount_factor</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.DiscountedUCBPolicy.__init__"><code class="docutils literal notranslate"><span class="pre">DiscountedUCBPolicy.__init__()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.DiscountedUCBPolicy.effective_n"><code class="docutils literal notranslate"><span class="pre">DiscountedUCBPolicy.effective_n</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.DiscountedUCBPolicy._calculate_confidence_interval"><code class="docutils literal notranslate"><span class="pre">DiscountedUCBPolicy._calculate_confidence_interval()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.DiscountedUCBPolicy.Q_values"><code class="docutils literal notranslate"><span class="pre">DiscountedUCBPolicy.Q_values</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.DiscountedUCBPolicy._get_actual_reward"><code class="docutils literal notranslate"><span class="pre">DiscountedUCBPolicy._get_actual_reward()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.DiscountedUCBPolicy._get_ucb_value"><code class="docutils literal notranslate"><span class="pre">DiscountedUCBPolicy._get_ucb_value()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.DiscountedUCBPolicy._update"><code class="docutils literal notranslate"><span class="pre">DiscountedUCBPolicy._update()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.DiscountedUCBPolicy._update_sliding_window"><code class="docutils literal notranslate"><span class="pre">DiscountedUCBPolicy._update_sliding_window()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.DiscountedUCBPolicy.get_reward_distribution"><code class="docutils literal notranslate"><span class="pre">DiscountedUCBPolicy.get_reward_distribution()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.DiscountedUCBPolicy.plot_distribution"><code class="docutils literal notranslate"><span class="pre">DiscountedUCBPolicy.plot_distribution()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.DiscountedUCBPolicy.reset"><code class="docutils literal notranslate"><span class="pre">DiscountedUCBPolicy.reset()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.DiscountedUCBPolicy.select_action"><code class="docutils literal notranslate"><span class="pre">DiscountedUCBPolicy.select_action()</span></code></a></li>
<li><a class="reference internal" href="#pymab.policies.ucb.DiscountedUCBPolicy.rewards_history"><code class="docutils literal notranslate"><span class="pre">DiscountedUCBPolicy.rewards_history</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#example-usage">Example Usage</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </div>
        </div>
    

      <div class="clearer"></div>
    </div>
    <div class="button_nav_wrapper">
        <div class="button_nav">
            <div class="left">
                
                <a href="index.html">
                    <span class="icon">&lt;</span><span>PyMAB documentation</span></a>
                
            </div>

            <div class="right">
                
                    <a href="game.html"><span>Game documentation</span><span class="icon">&gt;</span></a>
                
            </div>
        </div>
    </div>


    <div class="footer" role="contentinfo">
    &#169; Copyright 2024, Daniela Lopes.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.4.7.
    </div>

<p id="theme_credit">Styled using the <a href="https://github.com/piccolo-orm/piccolo_theme">Piccolo Theme</a></p>
  </body>
</html>